#!/usr/bin/env python3
"""
å˜æ›´æ—¥å¿—ç”Ÿæˆå™¨
ç”¨äºç”ŸæˆåŸºäºAIåˆ†æçš„ç‰ˆæœ¬å˜æ›´æ—¥å¿—

æ”¯æŒçš„è¿è¡Œæ¨¡å¼:
1. workflow_call: å·¥ä½œæµè°ƒç”¨æ¨¡å¼
2. auto_release: è‡ªåŠ¨å‘å¸ƒæ¨¡å¼
3. manual_optimize: æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼

ä¾èµ–: requests, gitpython
"""

import os
import sys
import json
import re
import argparse
import logging
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime
import subprocess
import requests
from dataclasses import dataclass
from enum import Enum
from pathlib import Path


class RunMode(Enum):
    WORKFLOW_CALL = "workflow_call"
    AUTO_RELEASE = "auto_release"
    MANUAL_OPTIMIZE = "manual_optimize"


@dataclass
class CommitInfo:
    hash: str
    message: str
    body: str = ""
    category: str = "OTHER"
    importance: int = 1


@dataclass
class AnalysisResult:
    categories: Dict[str, List[Dict[str, Any]]]
    summary: str
    highlights: List[str]


class AIChangelogGenerator:
    """AIå˜æ›´æ—¥å¿—ç”Ÿæˆå™¨ä¸»ç±»"""
    
    def __init__(self, github_token: str, deepseek_api_key: str, repo: str):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            github_token: GitHub Personal Access Token
            deepseek_api_key: DeepSeek APIå¯†é’¥
            repo: GitHubä»“åº“å (æ ¼å¼: owner/repo)
        """
        self.github_token = github_token
        self.deepseek_api_key = deepseek_api_key
        self.repo = repo
        self.logger = self._setup_logger()
        
        # åŠ è½½å¤–éƒ¨é…ç½®æ–‡ä»¶
        self._load_configs()
        
        # GitHub APIåŸºç¡€URL
        self.github_api_base = "https://api.github.com"
        self.deepseek_api_base = "https://api.deepseek.com/v1"
        
        # è¯·æ±‚å¤´è®¾ç½®
        self.github_headers = {
            "Authorization": f"token {github_token}",
            "Accept": "application/vnd.github.v3+json"
        }
        
        self.deepseek_headers = {
            "Authorization": f"Bearer {deepseek_api_key}",
            "Content-Type": "application/json"
        }
    
    def _load_configs(self):
        """åŠ è½½å¤–éƒ¨é…ç½®æ–‡ä»¶"""
        try:
            script_dir = Path(__file__).parent
            
            # åŠ è½½æç¤ºè¯é…ç½®
            with open(script_dir / 'prompts.json', 'r', encoding='utf-8') as f:
                self.prompts = json.load(f)
            
            # åŠ è½½APIé…ç½®
            with open(script_dir / 'config.json', 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            
            # åŠ è½½æ¨¡æ¿é…ç½®
            with open(script_dir / 'templates.json', 'r', encoding='utf-8') as f:
                self.templates = json.load(f)
            
            self.logger.info("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            raise Exception(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œè¯·ç¡®ä¿æ‰€æœ‰é…ç½®æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®: {e}")
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger("ai_changelog")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def validate_params(self, version: Optional[str] = None, release_id: Optional[str] = None, 
                       tag: Optional[str] = None, target: Optional[str] = None,
                       event_name: str = "workflow_dispatch") -> Tuple[RunMode, str, Optional[str]]:
        """
        éªŒè¯è¾“å…¥å‚æ•°å¹¶ç¡®å®šè¿è¡Œæ¨¡å¼
        
        Args:
            version: ç‰ˆæœ¬å· (è‡ªåŠ¨è§¦å‘æ—¶ä½¿ç”¨)
            release_id: Release ID (è‡ªåŠ¨è§¦å‘æ—¶ä½¿ç”¨)
            tag: æ ‡ç­¾ (æ—§ç‰ˆæ‰‹åŠ¨è§¦å‘å…¼å®¹)
            target: ç›®æ ‡ç‰ˆæœ¬æˆ–æ ‡ç­¾ (æ–°ç‰ˆæ‰‹åŠ¨è§¦å‘ä½¿ç”¨)
            event_name: äº‹ä»¶åç§°
            
        Returns:
            Tuple[è¿è¡Œæ¨¡å¼, ç‰ˆæœ¬å·, Release ID]
        """
        self.logger.info("ğŸ” éªŒè¯è¾“å…¥å‚æ•°...")
        
        if event_name == "workflow_call":
            # è‡ªåŠ¨è§¦å‘æ¨¡å¼ï¼šéœ€è¦versionå’Œrelease_id
            if not version or not release_id:
                raise ValueError("å·¥ä½œæµè°ƒç”¨æ¨¡å¼éœ€è¦æä¾›ç‰ˆæœ¬å·å’ŒRelease ID")
            mode = RunMode.WORKFLOW_CALL
            self.logger.info(f"ğŸ”— å·¥ä½œæµè°ƒç”¨æ¨¡å¼: ç‰ˆæœ¬ {version}, Release ID {release_id}")
            return mode, version, release_id
            
        else:
            # æ‰‹åŠ¨è§¦å‘æ¨¡å¼
            if target:
                # æ–°ç‰ˆæ‰‹åŠ¨è§¦å‘ï¼šä½¿ç”¨targetå‚æ•°
                if target.lower() == 'latest':
                    # è·å–æœ€æ–°çš„release
                    self.logger.info("ğŸ¯ ç›®æ ‡ä¸ºlatestï¼Œè·å–æœ€æ–°Release...")
                    latest_version, latest_release_id = self._get_latest_release()
                    mode = RunMode.MANUAL_OPTIMIZE
                    self.logger.info(f"ğŸ“ æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼: æœ€æ–°ç‰ˆæœ¬ {latest_version}")
                    return mode, latest_version, latest_release_id
                else:
                    # æŒ‡å®šç‰ˆæœ¬çš„æ‰‹åŠ¨è§¦å‘
                    mode = RunMode.MANUAL_OPTIMIZE
                    self.logger.info(f"ğŸ“ æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼: æŒ‡å®šç‰ˆæœ¬ {target}")
                    return mode, target, None
                    
            elif tag:
                # æ—§ç‰ˆæ‰‹åŠ¨è§¦å‘å…¼å®¹ï¼šä½¿ç”¨tagå‚æ•°
                mode = RunMode.MANUAL_OPTIMIZE
                self.logger.info(f"ğŸ“ æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼(å…¼å®¹): æ ‡ç­¾ {tag}")
                return mode, tag, None
                
            elif release_id:
                # æ—§ç‰ˆè‡ªåŠ¨è§¦å‘å…¼å®¹ï¼šæœ‰release_idä½†æ²¡æœ‰version
                if not version:
                    raise ValueError("è‡ªåŠ¨å‘å¸ƒæ¨¡å¼éœ€è¦æä¾›ç‰ˆæœ¬å·")
                mode = RunMode.AUTO_RELEASE
                self.logger.info(f"ğŸ¤– è‡ªåŠ¨å‘å¸ƒæ¨¡å¼(å…¼å®¹): ç‰ˆæœ¬ {version}, Release ID {release_id}")
                return mode, version, release_id
                
            else:
                raise ValueError("æ‰‹åŠ¨æ¨¡å¼éœ€è¦æä¾›targetå‚æ•°ï¼Œæˆ–ä½¿ç”¨å…¼å®¹çš„tagå‚æ•°")
    
    def _get_latest_release(self) -> Tuple[str, str]:
        """
        è·å–æœ€æ–°çš„Releaseä¿¡æ¯
        
        Returns:
            Tuple[ç‰ˆæœ¬æ ‡ç­¾, Release ID]
        """
        self.logger.info("ğŸ” è·å–æœ€æ–°Releaseä¿¡æ¯...")
        
        url = f"{self.github_api_base}/repos/{self.repo}/releases/latest"
        response = requests.get(url, headers=self.github_headers)
        
        if response.status_code != 200:
            error_msg = f"æ— æ³•è·å–æœ€æ–°Releaseä¿¡æ¯: {response.json().get('message', 'æœªçŸ¥é”™è¯¯')}"
            self.logger.error(f"âŒ {error_msg}")
            raise Exception(error_msg)
        
        release_data = response.json()
        tag_name = release_data['tag_name']
        release_id = str(release_data['id'])
        
        self.logger.info(f"âœ… è·å–åˆ°æœ€æ–°Release: {tag_name} (ID: {release_id})")
        
        return tag_name, release_id

    def get_release_info(self, mode: RunMode, version: str, release_id: Optional[str] = None) -> Tuple[str, str]:
        """
        è·å–Releaseä¿¡æ¯
        
        Args:
            mode: è¿è¡Œæ¨¡å¼
            version: ç‰ˆæœ¬å·
            release_id: Release ID (å¯é€‰)
            
        Returns:
            Tuple[Release ID, åŸå§‹å˜æ›´æ—¥å¿—]
        """
        self.logger.info("ğŸ“‹ è·å–Releaseä¿¡æ¯...")
        
        if mode == RunMode.AUTO_RELEASE and release_id:
            # é€šè¿‡Release IDè·å–ä¿¡æ¯
            url = f"{self.github_api_base}/repos/{self.repo}/releases/{release_id}"
        else:
            # é€šè¿‡æ ‡ç­¾è·å–ä¿¡æ¯
            url = f"{self.github_api_base}/repos/{self.repo}/releases/tags/{version}"
        
        response = requests.get(url, headers=self.github_headers)
        
        if response.status_code != 200:
            error_msg = f"æ— æ³•è·å–Releaseä¿¡æ¯: {response.json().get('message', 'æœªçŸ¥é”™è¯¯')}"
            self.logger.error(f"âŒ {error_msg}")
            raise Exception(error_msg)
        
        release_data = response.json()
        release_id = str(release_data['id'])
        original_changelog = release_data.get('body', '')
        
        self.logger.info(f"âœ… è·å–åˆ°Releaseä¿¡æ¯ï¼ŒID: {release_id}")
        self.logger.info(f"ğŸ“‹ åŸå§‹å˜æ›´æ—¥å¿—é•¿åº¦: {len(original_changelog)} å­—ç¬¦")
        
        return release_id, original_changelog
    
    def check_optimization_status(self, mode: RunMode, original_changelog: str) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–å˜æ›´æ—¥å¿—
        
        Args:
            mode: è¿è¡Œæ¨¡å¼
            original_changelog: åŸå§‹å˜æ›´æ—¥å¿—
            
        Returns:
            Tuple[æ˜¯å¦éœ€è¦ä¼˜åŒ–, å¤„ç†åçš„åŸå§‹å†…å®¹]
        """
        self.logger.info("ğŸ” æ£€æŸ¥å˜æ›´æ—¥å¿—ä¼˜åŒ–çŠ¶æ€...")
        
        if mode == RunMode.MANUAL_OPTIMIZE:
            self.logger.info("ğŸ“ æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼ï¼šå¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼Œæå–åŸå§‹å†…å®¹")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«AIä¼˜åŒ–æ ‡è®°å’ŒæŠ˜å åŒºåŸŸ
            if "<details>" in original_changelog and "æŸ¥çœ‹åŸå§‹æäº¤è®°å½•" in original_changelog:
                self.logger.info("ğŸ“‹ å‘ç°æŠ˜å åŒºåŸŸï¼Œæå–åŸå§‹æäº¤è®°å½•...")
                
                # æå–æŠ˜å åŒºåŸŸå†…å®¹
                details_pattern = r'<details>.*?<summary>.*?</summary>(.*?)</details>'
                match = re.search(details_pattern, original_changelog, re.DOTALL)
                
                if match:
                    extracted_content = match.group(1).strip()
                    # ç§»é™¤å¯èƒ½çš„HTMLæ ‡ç­¾å’Œç©ºç™½å­—ç¬¦
                    extracted_content = re.sub(r'^\s*\n+', '', extracted_content)
                    extracted_content = re.sub(r'\n+\s*$', '', extracted_content)
                    
                    if extracted_content and extracted_content != "æš‚æ— åŸå§‹è®°å½•":
                        self.logger.info(f"âœ… æˆåŠŸæå–åˆ°åŸå§‹æäº¤è®°å½•ï¼Œå†…å®¹é•¿åº¦: {len(extracted_content)} å­—ç¬¦")
                        return True, extracted_content
                    else:
                        self.logger.warning("âš ï¸ æŠ˜å åŒºåŸŸå†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆï¼Œå°†ä»Gitå†å²é‡æ–°è·å–")
                        return True, ""
                else:
                    self.logger.info("â„¹ï¸ æœªå‘ç°æœ‰æ•ˆçš„æŠ˜å åŒºåŸŸæ ¼å¼ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
                    return True, original_changelog
            else:
                self.logger.info("â„¹ï¸ æœªå‘ç°æŠ˜å åŒºåŸŸï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
                return True, original_changelog
        else:
            # è‡ªåŠ¨æ¨¡å¼æ£€æŸ¥
            if "AIç”Ÿæˆçš„å˜æ›´æ—¥å¿—æ‘˜è¦" in original_changelog:
                self.logger.warning("âš ï¸ æ­¤Releaseå·²åŒ…å«AIç”Ÿæˆçš„å˜æ›´æ—¥å¿—")
                self.logger.info("ğŸ¤– è‡ªåŠ¨æ¨¡å¼ï¼Œè·³è¿‡é‡å¤ä¼˜åŒ–")
                return False, original_changelog
            else:
                self.logger.info("âœ… å˜æ›´æ—¥å¿—æœªç»AIä¼˜åŒ–ï¼Œå¯ä»¥è¿›è¡Œä¼˜åŒ–")
                return True, original_changelog
    
    def get_git_commits(self, version: str) -> Tuple[List[CommitInfo], str, int]:
        """
        è·å–Gitæäº¤ä¿¡æ¯
        
        Args:
            version: å½“å‰ç‰ˆæœ¬æ ‡ç­¾
            
        Returns:
            Tuple[æäº¤åˆ—è¡¨, æäº¤èŒƒå›´æè¿°, æäº¤æ•°é‡]
        """
        self.logger.info("ğŸ“Š è·å–è¯¦ç»†çš„æäº¤ä¿¡æ¯...")
        self.logger.info(f"ğŸ¯ å½“å‰ç‰ˆæœ¬: {version}")
        
        try:
            # è·å–æ‰€æœ‰æ ‡ç­¾å¹¶æ’åº
            result = subprocess.run(
                ["git", "tag", "--sort=-version:refname"],
                capture_output=True, text=True, check=True
            )
            all_tags = [tag.strip() for tag in result.stdout.split('\n') if tag.strip()]
            
            # æ‰¾åˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬æ ‡ç­¾
            last_tag = None
            version_pattern = re.compile(r'^v?[0-9]+\.[0-9]+(\.[0-9]+)?.*$')
            
            for tag in all_tags:
                if tag != version and version_pattern.match(tag):
                    last_tag = tag
                    break
            
            # ç¡®å®šæäº¤èŒƒå›´
            if not last_tag:
                self.logger.info("ğŸ“‹ é¦–æ¬¡å‘å¸ƒï¼Œè·å–åˆ°å½“å‰ç‰ˆæœ¬çš„æ‰€æœ‰æäº¤è®°å½•")
                git_cmd = ["git", "log", version, "--pretty=format:%h|%s|%b", "--no-merges"]
                commit_range = f"åˆå§‹ç‰ˆæœ¬åˆ°{version}"
            else:
                self.logger.info(f"ğŸ“‹ è·å– {last_tag} åˆ° {version} ä¹‹é—´çš„æäº¤è®°å½•")
                git_cmd = ["git", "log", f"{last_tag}..{version}", "--pretty=format:%h|%s|%b", "--no-merges"]
                commit_range = f"{last_tag}..{version}"
            
            # æ‰§è¡ŒGitå‘½ä»¤è·å–æäº¤
            result = subprocess.run(git_cmd, capture_output=True, text=True, check=True)
            commits_raw = result.stdout.strip()
            
            if not commits_raw:
                self.logger.warning("âš ï¸ æœªè·å–åˆ°æäº¤è®°å½•ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
                
                # å°è¯•åŒ…å«åˆå¹¶æäº¤
                if last_tag:
                    git_cmd = ["git", "log", f"{last_tag}..{version}", "--pretty=format:%h|%s|%b"]
                    result = subprocess.run(git_cmd, capture_output=True, text=True, check=True)
                    commits_raw = result.stdout.strip()
                
                # å¦‚æœè¿˜æ˜¯ä¸ºç©ºï¼Œè·å–æœ€è¿‘çš„æäº¤
                if not commits_raw:
                    self.logger.info("ğŸ”„ è·å–æœ€è¿‘çš„æäº¤è®°å½•...")
                    git_cmd = ["git", "log", "--pretty=format:%h|%s|%b", "-n", "20"]
                    result = subprocess.run(git_cmd, capture_output=True, text=True, check=True)
                    commits_raw = result.stdout.strip()
                    commit_range = "æœ€è¿‘20ä¸ªæäº¤"
            
            # è§£ææäº¤ä¿¡æ¯
            commits = []
            if commits_raw:
                for line in commits_raw.split('\n'):
                    parts = line.split('|', 2)
                    if len(parts) >= 2 and parts[0]:
                        commit = CommitInfo(
                            hash=parts[0],
                            message=parts[1].strip(),
                            body=parts[2].strip() if len(parts) > 2 else ""
                        )
                        commits.append(commit)
            
            commit_count = len(commits)
            self.logger.info(f"âœ… è·å–åˆ° {commit_count} ä¸ªæäº¤è®°å½•")
            
            if commit_count == 0:
                raise Exception("æ— æ³•è·å–æœ‰æ•ˆçš„æäº¤è®°å½•")
            
            return commits, commit_range, commit_count
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"âŒ Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            raise Exception(f"Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
        except Exception as e:
            self.logger.error(f"âŒ è·å–æäº¤ä¿¡æ¯å¤±è´¥: {e}")
            raise

    def classify_commits(self, commits: List[CommitInfo]) -> Dict[str, List[CommitInfo]]:
        """
        å¯¹æäº¤è¿›è¡Œåˆ†ç±»
        
        Args:
            commits: æäº¤åˆ—è¡¨
            
        Returns:
            åˆ†ç±»åçš„æäº¤å­—å…¸
        """
        self.logger.info("ğŸ†• å¤„ç†Gitå†å²æäº¤è®°å½•...")
        
        categories = self.templates["categories"]
        patterns = self.templates["commit_patterns"]
        
        classified = {category: [] for category in categories.keys()}
        
        for commit in commits:
            clean_message = commit.message.strip()
            categorized = False
            
            # æŒ‰ä¼˜å…ˆçº§åŒ¹é…åˆ†ç±»
            for category, pattern in patterns.items():
                if category == "OTHER":
                    continue
                if re.match(pattern, clean_message, re.IGNORECASE):
                    commit.category = category
                    classified[category].append(commit)
                    categorized = True
                    break
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šåˆ†ç±»ï¼Œå½’ç±»ä¸ºOTHER
            if not categorized:
                commit.category = "OTHER"
                classified["OTHER"].append(commit)
        
        # æ‰“å°åˆ†ç±»ç»Ÿè®¡
        self.logger.info("ğŸ“Š åˆæ­¥åˆ†ç±»ç»Ÿè®¡:")
        for category, commits_list in classified.items():
            if commits_list:
                title, _ = categories[category]
                self.logger.info(f"  - {title}: {len(commits_list)}")
        
        return classified
    
    def call_deepseek_api(self, commits: List[CommitInfo]) -> Optional[AnalysisResult]:
        """
        è°ƒç”¨DeepSeek APIåˆ†ææäº¤
        
        Args:
            commits: æäº¤åˆ—è¡¨
            
        Returns:
            AIåˆ†æç»“æœï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        self.logger.info("ğŸ§  è°ƒç”¨DeepSeek APIè¿›è¡Œæ™ºèƒ½åˆ†æå’Œä¼˜åŒ–...")
        
        if not commits:
            self.logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„æäº¤æ•°æ®å¯å‘é€ç»™AI")
            return None
        
        # å‡†å¤‡æäº¤æ•°æ®
        commits_text = ""
        for commit in commits:
            commits_text += f"{commit.hash}|{commit.message}\n"
        
        self.logger.info(f"âœ… å‡†å¤‡å‘é€ç»™AIçš„æ•°æ®é•¿åº¦: {len(commits_text)} å­—ç¬¦")
        
        # æ„å»ºAPIè¯·æ±‚
        system_prompt = self.prompts["system_prompt"]
        user_prompt = self.prompts["user_prompt_template"].format(commits_text=commits_text)

        api_config = self.config["deepseek_api"]
        request_data = {
            "model": api_config["model"],
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": api_config["temperature"],
            "max_tokens": api_config["max_tokens"]
        }
        
        try:
            self.logger.info("ğŸ“¡ å‘é€APIè¯·æ±‚...")            
            response = requests.post(
                f"{self.deepseek_api_base}/chat/completions",
                headers=self.deepseek_headers,
                json=request_data,
                timeout=api_config["timeout"]
            )
            
            self.logger.info(f"ğŸ“Š APIå“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code != 200:
                error_msg = f"HTTPé”™è¯¯ {response.status_code}: {response.json().get('error', {}).get('message', 'æœªçŸ¥HTTPé”™è¯¯')}"
                self.logger.error(f"âŒ APIè°ƒç”¨HTTPé”™è¯¯: {error_msg}")
                return None
            
            response_data = response.json()
            
            if 'choices' not in response_data or not response_data['choices']:
                self.logger.error("âŒ APIå“åº”æ ¼å¼å¼‚å¸¸: ç¼ºå°‘choiceså­—æ®µ")
                return None
            
            ai_content = response_data['choices'][0]['message']['content']
            
            if not ai_content:
                self.logger.error("âŒ AIå“åº”å†…å®¹ä¸ºç©º")
                return None
            
            # å°è¯•è§£æJSONç»“æœ
            try:
                # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
                ai_data = json.loads(ai_content)
                self.logger.info("âœ… DeepSeek APIè°ƒç”¨æˆåŠŸ - ç›´æ¥JSONæ ¼å¼")
                
                return AnalysisResult(
                    categories=ai_data.get('categories', {}),
                    summary=ai_data.get('summary', 'AIæ™ºèƒ½åˆ†æçš„ç‰ˆæœ¬æ›´æ–°'),
                    highlights=ai_data.get('highlights', [])
                )
                
            except json.JSONDecodeError:
                # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–ä»£ç å—ä¸­çš„JSON
                self.logger.info("ğŸ”„ ç›´æ¥JSONè§£æå¤±è´¥ï¼Œå°è¯•æå–ä»£ç å—ä¸­çš„JSON...")
                
                # æŸ¥æ‰¾ä»£ç å—æ¨¡å¼: ```json ... ``` æˆ– ``` ... ```
                code_block_patterns = [
                    r'```json\s*(.*?)\s*```',
                    r'```\s*(.*?)\s*```'
                ]
                
                extracted_json = None
                for pattern in code_block_patterns:
                    match = re.search(pattern, ai_content, re.DOTALL)
                    if match:
                        extracted_json = match.group(1).strip()
                        self.logger.info(f"ğŸ” æ‰¾åˆ°ä»£ç å—ï¼Œæå–å†…å®¹é•¿åº¦: {len(extracted_json)} å­—ç¬¦")
                        break
                
                if extracted_json:
                    try:
                        ai_data = json.loads(extracted_json)
                        self.logger.info("âœ… DeepSeek APIè°ƒç”¨æˆåŠŸ - ä»£ç å—JSONæ ¼å¼")
                        
                        return AnalysisResult(
                            categories=ai_data.get('categories', {}),
                            summary=ai_data.get('summary', 'AIæ™ºèƒ½åˆ†æçš„ç‰ˆæœ¬æ›´æ–°'),
                            highlights=ai_data.get('highlights', [])
                        )
                        
                    except json.JSONDecodeError as e:
                        self.logger.warning(f"âš ï¸ ä»£ç å—ä¸­çš„JSONè§£æä¹Ÿå¤±è´¥: {e}")
                        self.logger.info(f"ğŸ” æå–çš„å†…å®¹å‰200å­—ç¬¦: {extracted_json[:200]}...")
                else:
                    self.logger.warning("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ä»£ç å—æ ¼å¼")
                
                # æ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±è´¥
                self.logger.warning("âš ï¸ AIè¿”å›å†…å®¹æ— æ³•è§£æä¸ºæœ‰æ•ˆJSONï¼Œä½¿ç”¨åŸºç¡€åˆ†æç»“æœ")
                self.logger.info(f"ğŸ” AIåŸå§‹è¿”å›å†…å®¹å‰200å­—ç¬¦: {ai_content[:200]}...")
                return None
                
        except requests.RequestException as e:
            self.logger.error(f"âŒ APIè¯·æ±‚å¤±è´¥: {e}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ DeepSeek APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def generate_changelog_with_ai(self, version: str, ai_analysis: AnalysisResult, 
                                  original_changelog: str, commits: List[CommitInfo]) -> str:
        """
        ä½¿ç”¨AIåˆ†æç»“æœç”Ÿæˆå˜æ›´æ—¥å¿—
        
        Args:
            version: ç‰ˆæœ¬å·
            ai_analysis: AIåˆ†æç»“æœ
            original_changelog: åŸå§‹å˜æ›´æ—¥å¿—
            commits: åŸå§‹æäº¤åˆ—è¡¨
            
        Returns:
            ç”Ÿæˆçš„å˜æ›´æ—¥å¿—
        """
        self.logger.info("ğŸ“Š AIæ™ºèƒ½åˆ†æå®Œæˆï¼Œå¼€å§‹ç”Ÿæˆä¼˜åŒ–å˜æ›´æ—¥å¿—...")
        
        template = self.templates["changelog_templates"]["ai_generated"]
        categories = self.templates["categories"]
        importance_icons = self.templates["importance_icons"]
        
        # æ„å»ºå˜æ›´æ—¥å¿—
        changelog = template["header"].format(version=version) + "\n\n"
        changelog += template["overview"].format(summary=ai_analysis.summary) + "\n"
        
        # æ·»åŠ ä¸»è¦äº®ç‚¹
        if ai_analysis.highlights:
            highlights_text = "\n".join(f"- {highlight}" for highlight in ai_analysis.highlights)
            changelog += template["highlights"].format(highlights=highlights_text)
        
        changelog += template["divider"]
        
        # æŒ‰ä¼˜å…ˆçº§ç”Ÿæˆå„ä¸ªåˆ†ç±»
        categories_order = ["FEATURE", "FIX", "PERF", "STYLE", "REFACTOR", "DOCS", "BUILD", "OTHER"]
        
        for category in categories_order:
            if category in ai_analysis.categories and ai_analysis.categories[category]:
                title, _ = categories[category]
                changelog += "\n" + template["category_header"].format(title=title) + "\n"
                
                # æŒ‰é‡è¦æ€§æ’åº
                items = ai_analysis.categories[category]
                sorted_items = sorted(items, key=lambda x: x.get('importance', 1), reverse=True)
                
                for item in sorted_items:
                    importance = item.get('importance', 1)
                    icon = importance_icons.get(str(importance), "â€¢")
                    message = item.get('message', '')
                    hash_val = item.get('hash', '')
                    
                    changelog += template["item_format"].format(
                        icon=icon, message=message, hash=hash_val
                    )
        
        # æ·»åŠ åŸå§‹å˜æ›´è®°å½•åˆ°æŠ˜å åŒºåŸŸ
        changelog += "\n\n<details>\n<summary>æŸ¥çœ‹åŸå§‹æäº¤è®°å½•</summary>\n\n"
        
        # å¦‚æœåŸå§‹å˜æ›´æ—¥å¿—ä¸ºç©ºï¼Œåˆ™ç”ŸæˆåŸºç¡€çš„æäº¤è®°å½•
        if not original_changelog or original_changelog.strip() == "":
            self.logger.info("ğŸ“ åŸå§‹å˜æ›´æ—¥å¿—ä¸ºç©ºï¼Œç”ŸæˆåŸºç¡€æäº¤è®°å½•ä½œä¸ºåŸå§‹å†…å®¹")
            basic_commits = []
            for commit in commits:
                basic_commits.append(f"- {commit.message} ({commit.hash})")
            original_changelog = "\n".join(basic_commits) if basic_commits else "æš‚æ— æäº¤è®°å½•"
        
        changelog += original_changelog
        changelog += "\n\n</details>"
        
        return changelog
    
    def generate_changelog_basic(self, version: str, classified_commits: Dict[str, List[CommitInfo]], 
                               original_changelog: str) -> str:
        """
        ä½¿ç”¨åŸºç¡€è§„åˆ™ç”Ÿæˆå˜æ›´æ—¥å¿—
        
        Args:
            version: ç‰ˆæœ¬å·
            classified_commits: åˆ†ç±»åçš„æäº¤
            original_changelog: åŸå§‹å˜æ›´æ—¥å¿—
            
        Returns:
            ç”Ÿæˆçš„å˜æ›´æ—¥å¿—
        """
        self.logger.info("ğŸ”„ ä½¿ç”¨åŸºç¡€é€»è¾‘ç”Ÿæˆå˜æ›´æ—¥å¿—...")
        
        template = self.templates["changelog_templates"]["basic_generated"]
        categories = self.templates["categories"]
        
        # æ„å»ºå˜æ›´æ—¥å¿—
        changelog = template["header"].format(version=version) + "\n\n"
        changelog += template["overview"] + template["divider"]
        
        # æŒ‰ä¼˜å…ˆçº§ç”Ÿæˆå„ä¸ªåˆ†ç±»
        categories_order = ["FEATURE", "FIX", "PERF", "STYLE", "REFACTOR", "DOCS", "BUILD", "OTHER"]
        
        for category in categories_order:
            if category in classified_commits and classified_commits[category]:
                title, _ = categories[category]
                changelog += "\n" + template["category_header"].format(title=title) + "\n"
                
                for commit in classified_commits[category]:
                    # æ¸…ç†æäº¤æ¶ˆæ¯
                    clean_message = commit.message
                    
                    # ä»é…ç½®è·å–æ¸…ç†è§„åˆ™
                    prefixes = self.templates.get("cleanup_patterns", [
                        r'^feat[:\s]*', r'^fix[:\s]*', r'^style[:\s]*', 
                        r'^refactor[:\s]*', r'^perf[:\s]*', r'^docs?[:\s]*', 
                        r'^build[:\s]*', r'^æ–°å¢\s*', r'^ä¿®å¤\s*', r'^ä¼˜åŒ–\s*'
                    ])
                    
                    for prefix in prefixes:
                        clean_message = re.sub(prefix, '', clean_message, flags=re.IGNORECASE)
                    
                    clean_message = clean_message.strip()
                    if not clean_message:
                        clean_message = commit.message
                    
                    changelog += template["item_format"].format(
                        message=clean_message, hash=commit.hash
                    )
        
        # æ·»åŠ åŸå§‹å˜æ›´è®°å½•åˆ°æŠ˜å åŒºåŸŸ
        changelog += "\n\n<details>\n<summary>æŸ¥çœ‹åŸå§‹æäº¤è®°å½•</summary>\n\n"
        
        # å¦‚æœåŸå§‹å˜æ›´æ—¥å¿—ä¸ºç©ºï¼Œåˆ™ç”ŸæˆåŸºç¡€çš„æäº¤è®°å½•
        if not original_changelog or original_changelog.strip() == "":
            self.logger.info("ğŸ“ åŸå§‹å˜æ›´æ—¥å¿—ä¸ºç©ºï¼Œç”ŸæˆåŸºç¡€æäº¤è®°å½•ä½œä¸ºåŸå§‹å†…å®¹")
            all_commits = []
            for category, commits_list in classified_commits.items():
                for commit in commits_list:
                    all_commits.append(f"- {commit.message} ({commit.hash})")
            original_changelog = "\n".join(all_commits) if all_commits else "æš‚æ— æäº¤è®°å½•"
        
        changelog += original_changelog
        changelog += "\n\n</details>"
        
        return changelog

    def update_release_changelog(self, release_id: str, changelog: str) -> bool:
        """
        æ›´æ–°Releaseçš„å˜æ›´æ—¥å¿—
        
        Args:
            release_id: Release ID
            changelog: æ–°çš„å˜æ›´æ—¥å¿—å†…å®¹
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        self.logger.info("ğŸ“ æ›´æ–°Releaseå˜æ›´æ—¥å¿—...")
        
        url = f"{self.github_api_base}/repos/{self.repo}/releases/{release_id}"
        
        update_data = {
            "body": changelog
        }
        
        try:
            response = requests.patch(url, headers=self.github_headers, json=update_data)
            
            if response.status_code == 200:
                release_data = response.json()
                self.logger.info("âœ… Releaseå˜æ›´æ—¥å¿—æ›´æ–°æˆåŠŸ")
                self.logger.info(f"ğŸ”— Release URL: {release_data.get('html_url', '')}")
                return True
            else:
                error_msg = response.json().get('message', 'æœªçŸ¥é”™è¯¯')
                self.logger.error(f"âŒ Releaseå˜æ›´æ—¥å¿—æ›´æ–°å¤±è´¥: {error_msg}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°Releaseå¤±è´¥: {e}")
            return False
    
    def generate_summary_report(self, mode: RunMode, version: str, release_id: str,
                              classified_commits: Dict[str, List[CommitInfo]],
                              ai_success: bool, ai_error: Optional[str] = None) -> str:
        """
        ç”Ÿæˆæ‰§è¡Œæ‘˜è¦æŠ¥å‘Š
        
        Args:
            mode: è¿è¡Œæ¨¡å¼
            version: ç‰ˆæœ¬å·
            release_id: Release ID
            classified_commits: åˆ†ç±»åçš„æäº¤
            ai_success: AIæ˜¯å¦æˆåŠŸ
            ai_error: AIé”™è¯¯ä¿¡æ¯
            
        Returns:
            æ‘˜è¦æŠ¥å‘Šæ–‡æœ¬
        """
        total_commits = sum(len(commits) for commits in classified_commits.values())
        
        # æ§åˆ¶å°å‹å¥½çš„æŠ¥å‘Šæ ¼å¼
        console_report = f"""
{'='*60}
ğŸ¤– AIå˜æ›´æ—¥å¿—ç”Ÿæˆå®Œæˆ
{'='*60}

ğŸ“‹ åŸºæœ¬ä¿¡æ¯:
  â€¢ è¿è¡Œæ¨¡å¼: {mode.value}
  â€¢ ç‰ˆæœ¬å·: {version}
  â€¢ Release ID: {release_id}

ğŸ¤– AIåˆ†æçŠ¶æ€:
  â€¢ DeepSeek API: {'âœ… è°ƒç”¨æˆåŠŸ' if ai_success else 'âŒ è°ƒç”¨å¤±è´¥'}
  â€¢ ç”Ÿæˆæ–¹å¼: {'ğŸ§  AIæ™ºèƒ½ç”Ÿæˆ' if ai_success else 'ğŸ“ åŸºç¡€è§„åˆ™ç”Ÿæˆ'}
"""
        
        if not ai_success and ai_error:
            console_report += f"  â€¢ å¤±è´¥åŸå› : {ai_error}\n"
        
        console_report += "\nğŸ“Š æäº¤ç»Ÿè®¡:\n"
        
        for category, commits_list in classified_commits.items():
            if commits_list:  # åªæ˜¾ç¤ºæœ‰å†…å®¹çš„åˆ†ç±»
                title, _ = self.templates["categories"][category]
                console_report += f"  â€¢ {title}: {len(commits_list)}\n"
        
        console_report += f"  â€¢ æ€»è®¡: {total_commits}\n"
        
        console_report += f"""
â±ï¸ æ‰§è¡Œä¿¡æ¯:
  â€¢ æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
  â€¢ çŠ¶æ€: {'âœ… AIå˜æ›´æ—¥å¿—ç”Ÿæˆå¹¶æ›´æ–°æˆåŠŸ' if ai_success else 'âš ï¸ å˜æ›´æ—¥å¿—ç”Ÿæˆå¹¶æ›´æ–°æˆåŠŸï¼ˆä½¿ç”¨åŸºç¡€è§„åˆ™ï¼‰'}

{'='*60}
"""
        
        # Markdownæ ¼å¼çš„æŠ¥å‘Šï¼ˆç”¨äºå¯èƒ½çš„å…¶ä»–ç”¨é€”ï¼‰
        markdown_report = f"""
## ğŸ¤– AIå˜æ›´æ—¥å¿—ç”Ÿæˆå®Œæˆ

### ğŸ“‹ åŸºæœ¬ä¿¡æ¯
| é¡¹ç›® | å€¼ |
|------|-----|
| è¿è¡Œæ¨¡å¼ | `{mode.value}` |
| ç‰ˆæœ¬å· | `{version}` |
| Release ID | `{release_id}` |

### ğŸ¤– AIåˆ†æçŠ¶æ€
| é¡¹ç›® | çŠ¶æ€ |
|------|------|
| DeepSeek API | {'âœ… è°ƒç”¨æˆåŠŸ' if ai_success else 'âŒ è°ƒç”¨å¤±è´¥'} |
| ç”Ÿæˆæ–¹å¼ | {'ğŸ§  AIæ™ºèƒ½ç”Ÿæˆ' if ai_success else 'ğŸ“ åŸºç¡€è§„åˆ™ç”Ÿæˆ'} |
"""
        
        if not ai_success and ai_error:
            markdown_report += f"| å¤±è´¥åŸå›  | {ai_error} |\n"
        
        markdown_report += f"""
### ğŸ“Š æäº¤ç»Ÿè®¡
| åˆ†ç±» | æ•°é‡ |
|------|------|
"""
        
        for category, commits_list in classified_commits.items():
            title, _ = self.templates["categories"][category]
            markdown_report += f"| {title} | {len(commits_list)} |\n"
        
        markdown_report += f"| **æ€»è®¡** | **{total_commits}** |\n"
        
        markdown_report += f"""
### â±ï¸ æ‰§è¡Œä¿¡æ¯
- **æ‰§è¡Œæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **çŠ¶æ€**: {'âœ… AIå˜æ›´æ—¥å¿—ç”Ÿæˆå¹¶æ›´æ–°æˆåŠŸ' if ai_success else 'âš ï¸ å˜æ›´æ—¥å¿—ç”Ÿæˆå¹¶æ›´æ–°æˆåŠŸï¼ˆä½¿ç”¨åŸºç¡€è§„åˆ™ï¼‰'}
"""
        
        # è¿”å›æ§åˆ¶å°å‹å¥½çš„æ ¼å¼
        return console_report
    
    def output_github_actions_summary(self, mode: RunMode, version: str, release_id: str,
                                    classified_commits: Dict[str, List[CommitInfo]],
                                    ai_success: bool, ai_error: Optional[str] = None):
        """
        è¾“å‡ºGitHub Actionsæ‘˜è¦ä¿¡æ¯
        
        Args:
            mode: è¿è¡Œæ¨¡å¼
            version: ç‰ˆæœ¬å·
            release_id: Release ID
            classified_commits: åˆ†ç±»åçš„æäº¤
            ai_success: AIæ˜¯å¦æˆåŠŸ
            ai_error: AIé”™è¯¯ä¿¡æ¯
        """
        # è¾“å‡ºåˆ°GitHub Actions Step Summary
        step_summary_file = os.getenv('GITHUB_STEP_SUMMARY')
        if step_summary_file:
            try:
                total_commits = sum(len(commits) for commits in classified_commits.values())
                
                summary_content = f"""# ğŸ¤– AIå˜æ›´æ—¥å¿—ç”ŸæˆæŠ¥å‘Š

## ğŸ“‹ æ‰§è¡Œæ¦‚è§ˆ
- **ç‰ˆæœ¬å·**: `{version}`
- **è¿è¡Œæ¨¡å¼**: `{mode.value}`
- **Release ID**: `{release_id}`
- **AIçŠ¶æ€**: {'âœ… æˆåŠŸ' if ai_success else 'âŒ å¤±è´¥'}
- **ç”Ÿæˆæ–¹å¼**: {'ğŸ§  AIæ™ºèƒ½ç”Ÿæˆ' if ai_success else 'ğŸ“ åŸºç¡€è§„åˆ™ç”Ÿæˆ'}
- **å¤„ç†æäº¤æ•°**: `{total_commits}`

## ğŸ“Š æäº¤åˆ†ç±»ç»Ÿè®¡
"""
                
                for category, commits_list in classified_commits.items():
                    if commits_list:
                        title, _ = self.templates["categories"][category]
                        summary_content += f"- **{title}**: {len(commits_list)} ä¸ªæäº¤\n"
                
                if not ai_success and ai_error:
                    summary_content += f"\n## âš ï¸ æ³¨æ„äº‹é¡¹\n- AI APIè°ƒç”¨å¤±è´¥: {ai_error}\n- å·²ä½¿ç”¨åŸºç¡€è§„åˆ™ç”Ÿæˆå˜æ›´æ—¥å¿—\n"
                
                summary_content += f"\n## âœ… æ‰§è¡Œç»“æœ\nå˜æ›´æ—¥å¿—å·²æˆåŠŸæ›´æ–°åˆ° Release é¡µé¢\n"
                
                with open(step_summary_file, 'w', encoding='utf-8') as f:
                    f.write(summary_content)
                
                self.logger.info("âœ… GitHub Actionsæ‘˜è¦å·²ç”Ÿæˆ")
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ ç”ŸæˆGitHub Actionsæ‘˜è¦å¤±è´¥: {e}")
        
        # è¾“å‡ºGitHub Actionså˜é‡
        github_output_file = os.getenv('GITHUB_OUTPUT')
        if github_output_file:
            try:
                with open(github_output_file, 'a', encoding='utf-8') as f:
                    f.write(f"ai_success={str(ai_success).lower()}\n")
                    f.write(f"total_commits={sum(len(commits) for commits in classified_commits.values())}\n")
                    f.write(f"generation_mode={'ai' if ai_success else 'basic'}\n")
            except Exception as e:
                self.logger.warning(f"âš ï¸ è®¾ç½®GitHub Actionsè¾“å‡ºå˜é‡å¤±è´¥: {e}")

    def run(self, version: Optional[str] = None, release_id: Optional[str] = None, 
           tag: Optional[str] = None, target: Optional[str] = None,
           event_name: str = "workflow_dispatch") -> bool:
        """
        è¿è¡ŒAIå˜æ›´æ—¥å¿—ç”Ÿæˆæµç¨‹
        
        Args:
            version: ç‰ˆæœ¬å· (è‡ªåŠ¨è§¦å‘æ—¶ä½¿ç”¨)
            release_id: Release ID (è‡ªåŠ¨è§¦å‘æ—¶ä½¿ç”¨)
            tag: æ ‡ç­¾ (æ—§ç‰ˆå…¼å®¹)
            target: ç›®æ ‡ç‰ˆæœ¬æˆ–æ ‡ç­¾ (æ–°ç‰ˆæ‰‹åŠ¨è§¦å‘ä½¿ç”¨)
            event_name: äº‹ä»¶åç§°
            
        Returns:
            æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
        """
        try:
            # 1. éªŒè¯å‚æ•°
            mode, final_version, final_release_id = self.validate_params(
                version, release_id, tag, target, event_name
            )
            
            # 2. è·å–Releaseä¿¡æ¯
            final_release_id, original_changelog = self.get_release_info(mode, final_version, final_release_id)
            
            # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
            need_optimize, processed_changelog = self.check_optimization_status(mode, original_changelog)
            
            if not need_optimize:
                self.logger.info("ğŸš« æ— éœ€ä¼˜åŒ–ï¼Œæµç¨‹ç»“æŸ")
                return True
            
            # 4. è·å–Gitæäº¤ä¿¡æ¯
            commits, commit_range, commit_count = self.get_git_commits(final_version)
            
            # 5. åˆ†ç±»æäº¤
            classified_commits = self.classify_commits(commits)
            
            # 6. å°è¯•AIåˆ†æ
            ai_analysis = self.call_deepseek_api(commits)
            ai_success = ai_analysis is not None
            ai_error = None if ai_success else "APIè°ƒç”¨å¤±è´¥"
            
            # 7. ç”Ÿæˆå˜æ›´æ—¥å¿—
            if ai_success:
                changelog = self.generate_changelog_with_ai(final_version, ai_analysis, processed_changelog, commits)
            else:
                changelog = self.generate_changelog_basic(final_version, classified_commits, processed_changelog)
            
            # 8. æ›´æ–°Release
            success = self.update_release_changelog(final_release_id, changelog)
            
            # 9. ç”Ÿæˆå’Œè¾“å‡ºæ‘˜è¦æŠ¥å‘Š
            report = self.generate_summary_report(mode, final_version, final_release_id, 
                                                 classified_commits, ai_success, ai_error)
            
            # è¾“å‡ºåˆ°æ§åˆ¶å°
            print(report)
            
            # è¾“å‡ºåˆ°GitHub Actions
            self.output_github_actions_summary(mode, final_version, final_release_id, 
                                             classified_commits, ai_success, ai_error)
            
            return success
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="AIå˜æ›´æ—¥å¿—ç”Ÿæˆå™¨")
    
    # æ–°ç‰ˆå‚æ•°
    parser.add_argument("--target", help="ç›®æ ‡ç‰ˆæœ¬æˆ–æ ‡ç­¾ï¼ˆæ‰‹åŠ¨è§¦å‘ä½¿ç”¨ï¼Œå¦‚ï¼šv1.0.0 æˆ– latestï¼‰")
    
    # å…¼å®¹æ—§ç‰ˆå‚æ•°
    parser.add_argument("--version", help="ç‰ˆæœ¬å·ï¼ˆè‡ªåŠ¨è§¦å‘ä½¿ç”¨ï¼‰")
    parser.add_argument("--release-id", help="Release IDï¼ˆè‡ªåŠ¨è§¦å‘ä½¿ç”¨ï¼‰")
    parser.add_argument("--tag", help="æ ‡ç­¾ï¼ˆæ—§ç‰ˆå…¼å®¹ï¼‰")
    
    # å…¶ä»–å‚æ•°
    parser.add_argument("--event-name", default="workflow_dispatch", help="äº‹ä»¶åç§°")
    parser.add_argument("--repo", help="GitHubä»“åº“å(owner/repo)")
    parser.add_argument("--github-token", help="GitHub Token")
    parser.add_argument("--deepseek-api-key", help="DeepSeek API Key")
    
    args = parser.parse_args()
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    github_token = args.github_token or os.getenv("GITHUB_TOKEN")
    deepseek_api_key = args.deepseek_api_key or os.getenv("DEEPSEEK_API_KEY")
    repo = args.repo or os.getenv("GITHUB_REPOSITORY")
    
    if not github_token:
        print("âŒ ç¼ºå°‘GitHub Tokenï¼Œè¯·è®¾ç½®GITHUB_TOKENç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨--github-tokenå‚æ•°")
        sys.exit(1)
    
    if not deepseek_api_key:
        print("âŒ ç¼ºå°‘DeepSeek API Keyï¼Œè¯·è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨--deepseek-api-keyå‚æ•°")
        sys.exit(1)
    
    if not repo:
        print("âŒ ç¼ºå°‘ä»“åº“ä¿¡æ¯ï¼Œè¯·è®¾ç½®GITHUB_REPOSITORYç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨--repoå‚æ•°")
        sys.exit(1)
    
    # åˆ›å»ºç”Ÿæˆå™¨å¹¶è¿è¡Œ
    generator = AIChangelogGenerator(github_token, deepseek_api_key, repo)
    
    success = generator.run(
        version=args.version,
        release_id=args.release_id,
        tag=args.tag,
        target=args.target,
        event_name=args.event_name
    )
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
