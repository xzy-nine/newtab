#!/usr/bin/env python3
"""
å˜æ›´æ—¥å¿—ç”Ÿæˆå™¨
ç”¨äºç”ŸæˆåŸºäºAIåˆ†æçš„ç‰ˆæœ¬å˜æ›´æ—¥å¿—

æ”¯æŒçš„è¿è¡Œæ¨¡å¼:
1. workflow_call: å·¥ä½œæµè°ƒç”¨æ¨¡å¼
2. auto_release: è‡ªåŠ¨å‘å¸ƒæ¨¡å¼
3. manual_optimize: æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼
4. batch_all: æ‰¹é‡å¤„ç†æ‰€æœ‰æ¨¡å¼

ä¾èµ–: requests, gitpython
"""

import os
import sys
import json
import re
import argparse
import logging
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime
import subprocess
import requests
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
import time


class RunMode(Enum):
    WORKFLOW_CALL = "workflow_call"
    AUTO_RELEASE = "auto_release"
    MANUAL_OPTIMIZE = "manual_optimize"
    BATCH_ALL = "batch_all"


@dataclass
class CommitInfo:
    hash: str
    message: str
    body: str = ""
    category: str = "OTHER"
    importance: int = 1


@dataclass
class AnalysisResult:
    categories: Dict[str, List[Dict[str, Any]]]
    summary: str
    highlights: List[str]


@dataclass
class BatchStats:
    """æ‰¹é‡å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
    total_releases: int = 0
    processed_releases: int = 0
    success_count: int = 0
    ai_success_count: int = 0
    skipped_count: int = 0
    error_count: int = 0
    total_commits: int = 0
    start_time: float = 0
    
    def __post_init__(self):
        self.start_time = time.time()


class AIChangelogGenerator:
    """AIå˜æ›´æ—¥å¿—ç”Ÿæˆå™¨ä¸»ç±»"""
    
    def __init__(self, github_token: str, deepseek_api_key: str, repo: str):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            github_token: GitHub Personal Access Token
            deepseek_api_key: DeepSeek APIå¯†é’¥
            repo: GitHubä»“åº“å (æ ¼å¼: owner/repo)
        """
        self.github_token = github_token
        self.deepseek_api_key = deepseek_api_key
        self.repo = repo
        self.logger = self._setup_logger()
        
        # æ‰¹é‡å¤„ç†ç»Ÿè®¡
        self.batch_stats = BatchStats()
        
        # åŠ è½½å¤–éƒ¨é…ç½®æ–‡ä»¶
        self._load_configs()
        
        # GitHub APIåŸºç¡€URL
        self.github_api_base = "https://api.github.com"
        self.deepseek_api_base = "https://api.deepseek.com/v1"
        
        # è¯·æ±‚å¤´è®¾ç½®
        self.github_headers = {
            "Authorization": f"token {github_token}",
            "Accept": "application/vnd.github.v3+json"
        }
        
        self.deepseek_headers = {
            "Authorization": f"Bearer {deepseek_api_key}",
            "Content-Type": "application/json"
        }
    
    def _load_configs(self):
        """åŠ è½½å¤–éƒ¨é…ç½®æ–‡ä»¶"""
        try:
            script_dir = Path(__file__).parent
            
            # åŠ è½½æç¤ºè¯é…ç½®
            with open(script_dir / 'prompts.json', 'r', encoding='utf-8') as f:
                self.prompts = json.load(f)
            
            # åŠ è½½APIé…ç½®
            with open(script_dir / 'config.json', 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            
            # åŠ è½½æ¨¡æ¿é…ç½®
            with open(script_dir / 'templates.json', 'r', encoding='utf-8') as f:
                self.templates = json.load(f)
            
            self.logger.info("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            raise Exception(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œè¯·ç¡®ä¿æ‰€æœ‰é…ç½®æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®: {e}")
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger("ai_changelog")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def validate_params(self, version: Optional[str] = None, release_id: Optional[str] = None, 
                       tag: Optional[str] = None, target: Optional[str] = None,
                       event_name: str = "workflow_dispatch") -> Tuple[RunMode, str, Optional[str]]:
        """
        éªŒè¯è¾“å…¥å‚æ•°å¹¶ç¡®å®šè¿è¡Œæ¨¡å¼
        
        Args:
            version: ç‰ˆæœ¬å· (è‡ªåŠ¨è§¦å‘æ—¶ä½¿ç”¨)
            release_id: Release ID (è‡ªåŠ¨è§¦å‘æ—¶ä½¿ç”¨)
            tag: æ ‡ç­¾ (æ—§ç‰ˆæ‰‹åŠ¨è§¦å‘å…¼å®¹)
            target: ç›®æ ‡ç‰ˆæœ¬æˆ–æ ‡ç­¾ (æ–°ç‰ˆæ‰‹åŠ¨è§¦å‘ä½¿ç”¨)
            event_name: äº‹ä»¶åç§°
            
        Returns:
            Tuple[è¿è¡Œæ¨¡å¼, ç‰ˆæœ¬å·, Release ID]
        """
        self.logger.info("ğŸ” éªŒè¯è¾“å…¥å‚æ•°...")
        
        if event_name == "workflow_call":
            # è‡ªåŠ¨è§¦å‘æ¨¡å¼ï¼šéœ€è¦versionå’Œrelease_id
            if not version or not release_id:
                raise ValueError("å·¥ä½œæµè°ƒç”¨æ¨¡å¼éœ€è¦æä¾›ç‰ˆæœ¬å·å’ŒRelease ID")
            mode = RunMode.WORKFLOW_CALL
            self.logger.info(f"ğŸ”— å·¥ä½œæµè°ƒç”¨æ¨¡å¼: ç‰ˆæœ¬ {version}, Release ID {release_id}")
            return mode, version, release_id
            
        else:
            # æ‰‹åŠ¨è§¦å‘æ¨¡å¼
            if target:
                # æ–°ç‰ˆæ‰‹åŠ¨è§¦å‘ï¼šä½¿ç”¨targetå‚æ•°
                if target.lower() == 'latest':
                    # è·å–æœ€æ–°çš„release
                    self.logger.info("ğŸ¯ ç›®æ ‡ä¸ºlatestï¼Œè·å–æœ€æ–°Release...")
                    latest_version, latest_release_id = self._get_latest_release()
                    mode = RunMode.MANUAL_OPTIMIZE
                    self.logger.info(f"ğŸ“ æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼: æœ€æ–°ç‰ˆæœ¬ {latest_version}")
                    return mode, latest_version, latest_release_id
                elif target.lower() == 'all':
                    # æ‰¹é‡å¤„ç†æ‰€æœ‰release
                    self.logger.info("ğŸ”„ ç›®æ ‡ä¸ºallï¼Œæ‰¹é‡å¤„ç†æ‰€æœ‰Release...")
                    mode = RunMode.BATCH_ALL
                    self.logger.info("ğŸ“¦ æ‰¹é‡å¤„ç†æ¨¡å¼: å¤„ç†æ‰€æœ‰Release")
                    return mode, "all", None
                else:
                    # æŒ‡å®šç‰ˆæœ¬çš„æ‰‹åŠ¨è§¦å‘
                    mode = RunMode.MANUAL_OPTIMIZE
                    self.logger.info(f"ğŸ“ æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼: æŒ‡å®šç‰ˆæœ¬ {target}")
                    return mode, target, None
                    
            elif tag:
                # æ—§ç‰ˆæ‰‹åŠ¨è§¦å‘å…¼å®¹ï¼šä½¿ç”¨tagå‚æ•°
                if tag.lower() == 'all':
                    mode = RunMode.BATCH_ALL
                    self.logger.info("ğŸ“¦ æ‰¹é‡å¤„ç†æ¨¡å¼(å…¼å®¹): å¤„ç†æ‰€æœ‰Release")
                    return mode, "all", None
                else:
                    mode = RunMode.MANUAL_OPTIMIZE
                    self.logger.info(f"ğŸ“ æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼(å…¼å®¹): æ ‡ç­¾ {tag}")
                    return mode, tag, None
                    
            elif release_id:
                # æ—§ç‰ˆè‡ªåŠ¨è§¦å‘å…¼å®¹ï¼šæœ‰release_idä½†æ²¡æœ‰version
                if not version:
                    raise ValueError("è‡ªåŠ¨å‘å¸ƒæ¨¡å¼éœ€è¦æä¾›ç‰ˆæœ¬å·")
                mode = RunMode.AUTO_RELEASE
                self.logger.info(f"ğŸ¤– è‡ªåŠ¨å‘å¸ƒæ¨¡å¼(å…¼å®¹): ç‰ˆæœ¬ {version}, Release ID {release_id}")
                return mode, version, release_id
                
            else:
                raise ValueError("æ‰‹åŠ¨æ¨¡å¼éœ€è¦æä¾›targetå‚æ•°ï¼Œæˆ–ä½¿ç”¨å…¼å®¹çš„tagå‚æ•°")
    
    def _get_latest_release(self) -> Tuple[str, str]:
        """
        è·å–æœ€æ–°çš„Releaseä¿¡æ¯
        
        Returns:
            Tuple[ç‰ˆæœ¬æ ‡ç­¾, Release ID]
        """
        self.logger.info("ğŸ” è·å–æœ€æ–°Releaseä¿¡æ¯...")
        
        url = f"{self.github_api_base}/repos/{self.repo}/releases/latest"
        response = requests.get(url, headers=self.github_headers)
        
        if response.status_code != 200:
            error_msg = f"æ— æ³•è·å–æœ€æ–°Releaseä¿¡æ¯: {response.json().get('message', 'æœªçŸ¥é”™è¯¯')}"
            self.logger.error(f"âŒ {error_msg}")
            raise Exception(error_msg)
        
        release_data = response.json()
        tag_name = release_data['tag_name']
        release_id = str(release_data['id'])
        
        self.logger.info(f"âœ… è·å–åˆ°æœ€æ–°Release: {tag_name} (ID: {release_id})")
        
        return tag_name, release_id

    def get_release_info(self, mode: RunMode, version: str, release_id: Optional[str] = None) -> Tuple[str, str]:
        """
        è·å–Releaseä¿¡æ¯
        
        Args:
            mode: è¿è¡Œæ¨¡å¼
            version: ç‰ˆæœ¬å·
            release_id: Release ID (å¯é€‰)
            
        Returns:
            Tuple[Release ID, åŸå§‹å˜æ›´æ—¥å¿—]
        """
        self.logger.info("ğŸ“‹ è·å–Releaseä¿¡æ¯...")
        
        if mode == RunMode.AUTO_RELEASE and release_id:
            # é€šè¿‡Release IDè·å–ä¿¡æ¯
            url = f"{self.github_api_base}/repos/{self.repo}/releases/{release_id}"
        else:
            # é€šè¿‡æ ‡ç­¾è·å–ä¿¡æ¯
            url = f"{self.github_api_base}/repos/{self.repo}/releases/tags/{version}"
        
        response = requests.get(url, headers=self.github_headers)
        
        if response.status_code != 200:
            error_msg = f"æ— æ³•è·å–Releaseä¿¡æ¯: {response.json().get('message', 'æœªçŸ¥é”™è¯¯')}"
            self.logger.error(f"âŒ {error_msg}")
            raise Exception(error_msg)
        
        release_data = response.json()
        release_id = str(release_data['id'])
        original_changelog = release_data.get('body', '')
        
        self.logger.info(f"âœ… è·å–åˆ°Releaseä¿¡æ¯ï¼ŒID: {release_id}")
        self.logger.info(f"ğŸ“‹ åŸå§‹å˜æ›´æ—¥å¿—é•¿åº¦: {len(original_changelog)} å­—ç¬¦")
        
        return release_id, original_changelog
    
    def check_optimization_status(self, mode: RunMode, original_changelog: str) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–å˜æ›´æ—¥å¿—
        
        Args:
            mode: è¿è¡Œæ¨¡å¼
            original_changelog: åŸå§‹å˜æ›´æ—¥å¿—
            
        Returns:
            Tuple[æ˜¯å¦éœ€è¦ä¼˜åŒ–, å¤„ç†åçš„åŸå§‹å†…å®¹]
        """
        self.logger.info("ğŸ” æ£€æŸ¥å˜æ›´æ—¥å¿—ä¼˜åŒ–çŠ¶æ€...")
        
        if mode == RunMode.MANUAL_OPTIMIZE:
            self.logger.info("ğŸ“ æ‰‹åŠ¨ä¼˜åŒ–æ¨¡å¼ï¼šå¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼Œæå–åŸå§‹å†…å®¹")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«AIä¼˜åŒ–æ ‡è®°å’ŒæŠ˜å åŒºåŸŸ
            if "<details>" in original_changelog and "æŸ¥çœ‹åŸå§‹æäº¤è®°å½•" in original_changelog:
                self.logger.info("ğŸ“‹ å‘ç°æŠ˜å åŒºåŸŸï¼Œæå–åŸå§‹æäº¤è®°å½•...")
                
                # æå–æŠ˜å åŒºåŸŸå†…å®¹
                details_pattern = r'<details>.*?<summary>.*?</summary>(.*?)</details>'
                match = re.search(details_pattern, original_changelog, re.DOTALL)
                
                if match:
                    extracted_content = match.group(1).strip()
                    # ç§»é™¤å¯èƒ½çš„HTMLæ ‡ç­¾å’Œç©ºç™½å­—ç¬¦
                    extracted_content = re.sub(r'^\s*\n+', '', extracted_content)
                    extracted_content = re.sub(r'\n+\s*$', '', extracted_content)
                    
                    if extracted_content and extracted_content != "æš‚æ— åŸå§‹è®°å½•":
                        self.logger.info(f"âœ… æˆåŠŸæå–åˆ°åŸå§‹æäº¤è®°å½•ï¼Œå†…å®¹é•¿åº¦: {len(extracted_content)} å­—ç¬¦")
                        return True, extracted_content
                    else:
                        self.logger.warning("âš ï¸ æŠ˜å åŒºåŸŸå†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆï¼Œå°†ä»Gitå†å²é‡æ–°è·å–")
                        return True, ""
                else:
                    self.logger.info("â„¹ï¸ æœªå‘ç°æœ‰æ•ˆçš„æŠ˜å åŒºåŸŸæ ¼å¼ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
                    return True, original_changelog
            else:
                self.logger.info("â„¹ï¸ æœªå‘ç°æŠ˜å åŒºåŸŸï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
                return True, original_changelog
        else:
            # è‡ªåŠ¨æ¨¡å¼æ£€æŸ¥
            if "AIç”Ÿæˆçš„å˜æ›´æ—¥å¿—æ‘˜è¦" in original_changelog:
                self.logger.warning("âš ï¸ æ­¤Releaseå·²åŒ…å«AIç”Ÿæˆçš„å˜æ›´æ—¥å¿—")
                self.logger.info("ğŸ¤– è‡ªåŠ¨æ¨¡å¼ï¼Œè·³è¿‡é‡å¤ä¼˜åŒ–")
                return False, original_changelog
            else:
                self.logger.info("âœ… å˜æ›´æ—¥å¿—æœªç»AIä¼˜åŒ–ï¼Œå¯ä»¥è¿›è¡Œä¼˜åŒ–")
                return True, original_changelog
    
    def get_git_commits(self, version: str) -> Tuple[List[CommitInfo], str, int]:
        """
        è·å–Gitæäº¤ä¿¡æ¯
        
        Args:
            version: å½“å‰ç‰ˆæœ¬æ ‡ç­¾
            
        Returns:
            Tuple[æäº¤åˆ—è¡¨, æäº¤èŒƒå›´æè¿°, æäº¤æ•°é‡]
        """
        self.logger.info("ğŸ“Š è·å–è¯¦ç»†çš„æäº¤ä¿¡æ¯...")
        self.logger.info(f"ğŸ¯ å½“å‰ç‰ˆæœ¬: {version}")
        
        try:
            # è·å–æ‰€æœ‰æ ‡ç­¾å¹¶æ’åº
            result = subprocess.run(
                ["git", "tag", "--sort=-version:refname"],
                capture_output=True, text=True, check=True
            )
            all_tags = [tag.strip() for tag in result.stdout.split('\n') if tag.strip()]
            
            # æ‰¾åˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬æ ‡ç­¾
            last_tag = None
            version_pattern = re.compile(r'^v?[0-9]+\.[0-9]+(\.[0-9]+)?.*$')
            
            for tag in all_tags:
                if tag != version and version_pattern.match(tag):
                    last_tag = tag
                    break
            
            # ç¡®å®šæäº¤èŒƒå›´
            if not last_tag:
                self.logger.info("ğŸ“‹ é¦–æ¬¡å‘å¸ƒï¼Œè·å–åˆ°å½“å‰ç‰ˆæœ¬çš„æ‰€æœ‰æäº¤è®°å½•")
                git_cmd = ["git", "log", version, "--pretty=format:%h|%s|%b", "--no-merges"]
                commit_range = f"åˆå§‹ç‰ˆæœ¬åˆ°{version}"
            else:
                self.logger.info(f"ğŸ“‹ è·å– {last_tag} åˆ° {version} ä¹‹é—´çš„æäº¤è®°å½•")
                git_cmd = ["git", "log", f"{last_tag}..{version}", "--pretty=format:%h|%s|%b", "--no-merges"]
                commit_range = f"{last_tag}..{version}"
            
            # æ‰§è¡ŒGitå‘½ä»¤è·å–æäº¤
            result = subprocess.run(git_cmd, capture_output=True, text=True, check=True)
            commits_raw = result.stdout.strip()
            
            if not commits_raw:
                self.logger.warning("âš ï¸ æœªè·å–åˆ°æäº¤è®°å½•ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
                
                # å°è¯•åŒ…å«åˆå¹¶æäº¤
                if last_tag:
                    git_cmd = ["git", "log", f"{last_tag}..{version}", "--pretty=format:%h|%s|%b"]
                    result = subprocess.run(git_cmd, capture_output=True, text=True, check=True)
                    commits_raw = result.stdout.strip()
                
                # å¦‚æœè¿˜æ˜¯ä¸ºç©ºï¼Œè·å–æœ€è¿‘çš„æäº¤
                if not commits_raw:
                    self.logger.info("ğŸ”„ è·å–æœ€è¿‘çš„æäº¤è®°å½•...")
                    git_cmd = ["git", "log", "--pretty=format:%h|%s|%b", "-n", "20"]
                    result = subprocess.run(git_cmd, capture_output=True, text=True, check=True)
                    commits_raw = result.stdout.strip()
                    commit_range = "æœ€è¿‘20ä¸ªæäº¤"
            
            # è§£ææäº¤ä¿¡æ¯
            commits = []
            if commits_raw:
                for line in commits_raw.split('\n'):
                    parts = line.split('|', 2)
                    if len(parts) >= 2 and parts[0]:
                        commit = CommitInfo(
                            hash=parts[0],
                            message=parts[1].strip(),
                            body=parts[2].strip() if len(parts) > 2 else ""
                        )
                        commits.append(commit)
            
            commit_count = len(commits)
            self.logger.info(f"âœ… è·å–åˆ° {commit_count} ä¸ªæäº¤è®°å½•")
            
            if commit_count == 0:
                raise Exception("æ— æ³•è·å–æœ‰æ•ˆçš„æäº¤è®°å½•")
            
            return commits, commit_range, commit_count
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"âŒ Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            raise Exception(f"Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
        except Exception as e:
            self.logger.error(f"âŒ è·å–æäº¤ä¿¡æ¯å¤±è´¥: {e}")
            raise

    def classify_commits(self, commits: List[CommitInfo]) -> Dict[str, List[CommitInfo]]:
        """
        å¯¹æäº¤è¿›è¡Œåˆ†ç±»
        
        Args:
            commits: æäº¤åˆ—è¡¨
            
        Returns:
            åˆ†ç±»åçš„æäº¤å­—å…¸
        """
        self.logger.info("ğŸ†• å¤„ç†Gitå†å²æäº¤è®°å½•...")
        
        categories = self.templates["categories"]
        patterns = self.templates["commit_patterns"]
        
        classified = {category: [] for category in categories.keys()}
        
        for commit in commits:
            clean_message = commit.message.strip()
            categorized = False
            
            # æŒ‰ä¼˜å…ˆçº§åŒ¹é…åˆ†ç±»
            for category, pattern in patterns.items():
                if category == "OTHER":
                    continue
                if re.match(pattern, clean_message, re.IGNORECASE):
                    commit.category = category
                    classified[category].append(commit)
                    categorized = True
                    break
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šåˆ†ç±»ï¼Œå½’ç±»ä¸ºOTHER
            if not categorized:
                commit.category = "OTHER"
                classified["OTHER"].append(commit)
        
        # æ‰“å°åˆ†ç±»ç»Ÿè®¡
        self.logger.info("ğŸ“Š åˆæ­¥åˆ†ç±»ç»Ÿè®¡:")
        for category, commits_list in classified.items():
            if commits_list:
                title, _ = categories[category]
                self.logger.info(f"  - {title}: {len(commits_list)}")
        
        return classified
    
    def call_deepseek_api(self, commits: List[CommitInfo]) -> Optional[AnalysisResult]:
        """
        è°ƒç”¨DeepSeek APIåˆ†ææäº¤
        
        Args:
            commits: æäº¤åˆ—è¡¨
            
        Returns:
            AIåˆ†æç»“æœï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        self.logger.info("ğŸ§  è°ƒç”¨DeepSeek APIè¿›è¡Œæ™ºèƒ½åˆ†æå’Œä¼˜åŒ–...")
        
        if not commits:
            self.logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„æäº¤æ•°æ®å¯å‘é€ç»™AI")
            return None
        
        # å‡†å¤‡æäº¤æ•°æ®
        commits_text = ""
        for commit in commits:
            commits_text += f"{commit.hash}|{commit.message}\n"
        
        self.logger.info(f"âœ… å‡†å¤‡å‘é€ç»™AIçš„æ•°æ®é•¿åº¦: {len(commits_text)} å­—ç¬¦")
        
        # æ„å»ºAPIè¯·æ±‚
        system_prompt = self.prompts["system_prompt"]
        user_prompt = self.prompts["user_prompt_template"].format(commits_text=commits_text)

        api_config = self.config["deepseek_api"]
        request_data = {
            "model": api_config["model"],
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": api_config["temperature"],
            "max_tokens": api_config["max_tokens"]
        }
        
        try:
            self.logger.info("ğŸ“¡ å‘é€APIè¯·æ±‚...")            
            response = requests.post(
                f"{self.deepseek_api_base}/chat/completions",
                headers=self.deepseek_headers,
                json=request_data,
                timeout=api_config["timeout"]
            )
            
            self.logger.info(f"ğŸ“Š APIå“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code != 200:
                error_msg = f"HTTPé”™è¯¯ {response.status_code}: {response.json().get('error', {}).get('message', 'æœªçŸ¥HTTPé”™è¯¯')}"
                self.logger.error(f"âŒ APIè°ƒç”¨HTTPé”™è¯¯: {error_msg}")
                return None
            
            response_data = response.json()
            
            if 'choices' not in response_data or not response_data['choices']:
                self.logger.error("âŒ APIå“åº”æ ¼å¼å¼‚å¸¸: ç¼ºå°‘choiceså­—æ®µ")
                return None
            
            ai_content = response_data['choices'][0]['message']['content']
            
            if not ai_content:
                self.logger.error("âŒ AIå“åº”å†…å®¹ä¸ºç©º")
                return None
            
            # å°è¯•è§£æJSONç»“æœ
            try:
                # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
                ai_data = json.loads(ai_content)
                self.logger.info("âœ… DeepSeek APIè°ƒç”¨æˆåŠŸ - ç›´æ¥JSONæ ¼å¼")
                
                return AnalysisResult(
                    categories=ai_data.get('categories', {}),
                    summary=ai_data.get('summary', 'AIæ™ºèƒ½åˆ†æçš„ç‰ˆæœ¬æ›´æ–°'),
                    highlights=ai_data.get('highlights', [])
                )
                
            except json.JSONDecodeError:
                # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–ä»£ç å—ä¸­çš„JSON
                self.logger.info("ğŸ”„ ç›´æ¥JSONè§£æå¤±è´¥ï¼Œå°è¯•æå–ä»£ç å—ä¸­çš„JSON...")
                
                # æŸ¥æ‰¾ä»£ç å—æ¨¡å¼: ```json ... ``` æˆ– ``` ... ```
                code_block_patterns = [
                    r'```json\s*(.*?)\s*```',
                    r'```\s*(.*?)\s*```'
                ]
                
                extracted_json = None
                for pattern in code_block_patterns:
                    match = re.search(pattern, ai_content, re.DOTALL)
                    if match:
                        extracted_json = match.group(1).strip()
                        self.logger.info(f"ğŸ” æ‰¾åˆ°ä»£ç å—ï¼Œæå–å†…å®¹é•¿åº¦: {len(extracted_json)} å­—ç¬¦")
                        break
                
                if extracted_json:
                    try:
                        ai_data = json.loads(extracted_json)
                        self.logger.info("âœ… DeepSeek APIè°ƒç”¨æˆåŠŸ - ä»£ç å—JSONæ ¼å¼")
                        
                        return AnalysisResult(
                            categories=ai_data.get('categories', {}),
                            summary=ai_data.get('summary', 'AIæ™ºèƒ½åˆ†æçš„ç‰ˆæœ¬æ›´æ–°'),
                            highlights=ai_data.get('highlights', [])
                        )
                        
                    except json.JSONDecodeError as e:
                        self.logger.warning(f"âš ï¸ ä»£ç å—ä¸­çš„JSONè§£æä¹Ÿå¤±è´¥: {e}")
                        self.logger.info(f"ğŸ” æå–çš„å†…å®¹å‰200å­—ç¬¦: {extracted_json[:200]}...")
                else:
                    self.logger.warning("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ä»£ç å—æ ¼å¼")
                
                # æ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±è´¥
                self.logger.warning("âš ï¸ AIè¿”å›å†…å®¹æ— æ³•è§£æä¸ºæœ‰æ•ˆJSONï¼Œä½¿ç”¨åŸºç¡€åˆ†æç»“æœ")
                self.logger.info(f"ğŸ” AIåŸå§‹è¿”å›å†…å®¹å‰200å­—ç¬¦: {ai_content[:200]}...")
                return None
                
        except requests.RequestException as e:
            self.logger.error(f"âŒ APIè¯·æ±‚å¤±è´¥: {e}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ DeepSeek APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def generate_changelog_with_ai(self, version: str, ai_analysis: AnalysisResult, 
                                  original_changelog: str, commits: List[CommitInfo]) -> str:
        """
        ä½¿ç”¨AIåˆ†æç»“æœç”Ÿæˆå˜æ›´æ—¥å¿—
        
        Args:
            version: ç‰ˆæœ¬å·
            ai_analysis: AIåˆ†æç»“æœ
            original_changelog: åŸå§‹å˜æ›´æ—¥å¿—
            commits: åŸå§‹æäº¤åˆ—è¡¨
            
        Returns:
            ç”Ÿæˆçš„å˜æ›´æ—¥å¿—
        """
        self.logger.info("ğŸ“Š AIæ™ºèƒ½åˆ†æå®Œæˆï¼Œå¼€å§‹ç”Ÿæˆä¼˜åŒ–å˜æ›´æ—¥å¿—...")
        
        template = self.templates["changelog_templates"]["ai_generated"]
        categories = self.templates["categories"]
        importance_icons = self.templates["importance_icons"]
        
        # æ„å»ºå˜æ›´æ—¥å¿—
        changelog = template["header"].format(version=version) + "\n\n"
        changelog += template["overview"].format(summary=ai_analysis.summary) + "\n"
        
        # æ·»åŠ ä¸»è¦äº®ç‚¹
        if ai_analysis.highlights:
            highlights_text = "\n".join(f"- {highlight}" for highlight in ai_analysis.highlights)
            changelog += template["highlights"].format(highlights=highlights_text)
        
        changelog += template["divider"]
        
        # æŒ‰ä¼˜å…ˆçº§ç”Ÿæˆå„ä¸ªåˆ†ç±»
        categories_order = ["FEATURE", "FIX", "PERF", "STYLE", "REFACTOR", "DOCS", "BUILD", "OTHER"]
        
        for category in categories_order:
            if category in ai_analysis.categories and ai_analysis.categories[category]:
                title, _ = categories[category]
                changelog += "\n" + template["category_header"].format(title=title) + "\n"
                
                # æŒ‰é‡è¦æ€§æ’åº
                items = ai_analysis.categories[category]
                sorted_items = sorted(items, key=lambda x: x.get('importance', 1), reverse=True)
                
                for item in sorted_items:
                    importance = item.get('importance', 1)
                    icon = importance_icons.get(str(importance), "â€¢")
                    message = item.get('message', '')
                    hash_val = item.get('hash', '')
                    
                    changelog += template["item_format"].format(
                        icon=icon, message=message, hash=hash_val
                    )
        
        # æ·»åŠ åŸå§‹å˜æ›´è®°å½•åˆ°æŠ˜å åŒºåŸŸ
        changelog += "\n\n<details>\n<summary>æŸ¥çœ‹åŸå§‹æäº¤è®°å½•</summary>\n\n"
        
        # å¦‚æœåŸå§‹å˜æ›´æ—¥å¿—ä¸ºç©ºï¼Œåˆ™ç”ŸæˆåŸºç¡€çš„æäº¤è®°å½•
        if not original_changelog or original_changelog.strip() == "":
            self.logger.info("ğŸ“ åŸå§‹å˜æ›´æ—¥å¿—ä¸ºç©ºï¼Œç”ŸæˆåŸºç¡€æäº¤è®°å½•ä½œä¸ºåŸå§‹å†…å®¹")
            basic_commits = []
            for commit in commits:
                basic_commits.append(f"- {commit.message} ({commit.hash})")
            original_changelog = "\n".join(basic_commits) if basic_commits else "æš‚æ— æäº¤è®°å½•"
        
        changelog += original_changelog
        changelog += "\n\n</details>"
        
        return changelog
    
    def generate_changelog_basic(self, version: str, classified_commits: Dict[str, List[CommitInfo]], 
                               original_changelog: str) -> str:
        """
        ä½¿ç”¨åŸºç¡€è§„åˆ™ç”Ÿæˆå˜æ›´æ—¥å¿—
        
        Args:
            version: ç‰ˆæœ¬å·
            classified_commits: åˆ†ç±»åçš„æäº¤
            original_changelog: åŸå§‹å˜æ›´æ—¥å¿—
            
        Returns:
            ç”Ÿæˆçš„å˜æ›´æ—¥å¿—
        """
        self.logger.info("ğŸ”„ ä½¿ç”¨åŸºç¡€é€»è¾‘ç”Ÿæˆå˜æ›´æ—¥å¿—...")
        
        template = self.templates["changelog_templates"]["basic_generated"]
        categories = self.templates["categories"]
        
        # æ„å»ºå˜æ›´æ—¥å¿—
        changelog = template["header"].format(version=version) + "\n\n"
        changelog += template["overview"] + template["divider"]
        
        # æŒ‰ä¼˜å…ˆçº§ç”Ÿæˆå„ä¸ªåˆ†ç±»
        categories_order = ["FEATURE", "FIX", "PERF", "STYLE", "REFACTOR", "DOCS", "BUILD", "OTHER"]
        
        for category in categories_order:
            if category in classified_commits and classified_commits[category]:
                title, _ = categories[category]
                changelog += "\n" + template["category_header"].format(title=title) + "\n"
                
                for commit in classified_commits[category]:
                    # æ¸…ç†æäº¤æ¶ˆæ¯
                    clean_message = commit.message
                    
                    # ä»é…ç½®è·å–æ¸…ç†è§„åˆ™
                    prefixes = self.templates.get("cleanup_patterns", [
                        r'^feat[:\s]*', r'^fix[:\s]*', r'^style[:\s]*', 
                        r'^refactor[:\s]*', r'^perf[:\s]*', r'^docs?[:\s]*', 
                        r'^build[:\s]*', r'^æ–°å¢\s*', r'^ä¿®å¤\s*', r'^ä¼˜åŒ–\s*'
                    ])
                    
                    for prefix in prefixes:
                        clean_message = re.sub(prefix, '', clean_message, flags=re.IGNORECASE)
                    
                    clean_message = clean_message.strip()
                    if not clean_message:
                        clean_message = commit.message
                    
                    changelog += template["item_format"].format(
                        message=clean_message, hash=commit.hash
                    )
        
        # æ·»åŠ åŸå§‹å˜æ›´è®°å½•åˆ°æŠ˜å åŒºåŸŸ
        changelog += "\n\n<details>\n<summary>æŸ¥çœ‹åŸå§‹æäº¤è®°å½•</summary>\n\n"
        
        # å¦‚æœåŸå§‹å˜æ›´æ—¥å¿—ä¸ºç©ºï¼Œåˆ™ç”ŸæˆåŸºç¡€çš„æäº¤è®°å½•
        if not original_changelog or original_changelog.strip() == "":
            self.logger.info("ğŸ“ åŸå§‹å˜æ›´æ—¥å¿—ä¸ºç©ºï¼Œç”ŸæˆåŸºç¡€æäº¤è®°å½•ä½œä¸ºåŸå§‹å†…å®¹")
            all_commits = []
            for category, commits_list in classified_commits.items():
                for commit in commits_list:
                    all_commits.append(f"- {commit.message} ({commit.hash})")
            original_changelog = "\n".join(all_commits) if all_commits else "æš‚æ— æäº¤è®°å½•"
        
        changelog += original_changelog
        changelog += "\n\n</details>"
        
        return changelog

    def update_release_changelog(self, release_id: str, changelog: str) -> bool:
        """
        æ›´æ–°Releaseçš„å˜æ›´æ—¥å¿—
        
        Args:
            release_id: Release ID
            changelog: æ–°çš„å˜æ›´æ—¥å¿—å†…å®¹
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        self.logger.info("ğŸ“ æ›´æ–°Releaseå˜æ›´æ—¥å¿—...")
        
        url = f"{self.github_api_base}/repos/{self.repo}/releases/{release_id}"
        
        update_data = {
            "body": changelog
        }
        
        try:
            response = requests.patch(url, headers=self.github_headers, json=update_data)
            
            if response.status_code == 200:
                release_data = response.json()
                self.logger.info("âœ… Releaseå˜æ›´æ—¥å¿—æ›´æ–°æˆåŠŸ")
                self.logger.info(f"ğŸ”— Release URL: {release_data.get('html_url', '')}")
                return True
            else:
                error_msg = response.json().get('message', 'æœªçŸ¥é”™è¯¯')
                self.logger.error(f"âŒ Releaseå˜æ›´æ—¥å¿—æ›´æ–°å¤±è´¥: {error_msg}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°Releaseå¤±è´¥: {e}")
            return False
    
    def generate_summary_report(self, mode: RunMode, version: str, release_id: str,
                              classified_commits: Dict[str, List[CommitInfo]],
                              ai_success: bool, ai_error: Optional[str] = None) -> str:
        """
        ç”Ÿæˆæ‰§è¡Œæ‘˜è¦æŠ¥å‘Š
        
        Args:
            mode: è¿è¡Œæ¨¡å¼
            version: ç‰ˆæœ¬å·
            release_id: Release ID
            classified_commits: åˆ†ç±»åçš„æäº¤
            ai_success: AIæ˜¯å¦æˆåŠŸ
            ai_error: AIé”™è¯¯ä¿¡æ¯
            
        Returns:
            æ‘˜è¦æŠ¥å‘Šæ–‡æœ¬
        """
        total_commits = sum(len(commits) for commits in classified_commits.values())
        
        # æ§åˆ¶å°å‹å¥½çš„æŠ¥å‘Šæ ¼å¼
        console_report = f"""
{'='*60}
ğŸ¤– AIå˜æ›´æ—¥å¿—ç”Ÿæˆå®Œæˆ
{'='*60}

ğŸ“‹ åŸºæœ¬ä¿¡æ¯:
  â€¢ è¿è¡Œæ¨¡å¼: {mode.value}
  â€¢ ç‰ˆæœ¬å·: {version}
  â€¢ Release ID: {release_id}

ğŸ¤– AIåˆ†æçŠ¶æ€:
  â€¢ DeepSeek API: {'âœ… è°ƒç”¨æˆåŠŸ' if ai_success else 'âŒ è°ƒç”¨å¤±è´¥'}
  â€¢ ç”Ÿæˆæ–¹å¼: {'ğŸ§  AIæ™ºèƒ½ç”Ÿæˆ' if ai_success else 'ğŸ“ åŸºç¡€è§„åˆ™ç”Ÿæˆ'}
"""
        
        if not ai_success and ai_error:
            console_report += f"  â€¢ å¤±è´¥åŸå› : {ai_error}\n"
        
        console_report += "\nğŸ“Š æäº¤ç»Ÿè®¡:\n"
        
        for category, commits_list in classified_commits.items():
            if commits_list:  # åªæ˜¾ç¤ºæœ‰å†…å®¹çš„åˆ†ç±»
                title, _ = self.templates["categories"][category]
                console_report += f"  â€¢ {title}: {len(commits_list)}\n"
        
        console_report += f"  â€¢ æ€»è®¡: {total_commits}\n"
        
        console_report += f"""
â±ï¸ æ‰§è¡Œä¿¡æ¯:
  â€¢ æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
  â€¢ çŠ¶æ€: {'âœ… AIå˜æ›´æ—¥å¿—ç”Ÿæˆå¹¶æ›´æ–°æˆåŠŸ' if ai_success else 'âš ï¸ å˜æ›´æ—¥å¿—ç”Ÿæˆå¹¶æ›´æ–°æˆåŠŸï¼ˆä½¿ç”¨åŸºç¡€è§„åˆ™ï¼‰'}

{'='*60}
"""
        
        return console_report
    
    def output_github_actions_summary(self, mode: RunMode, version: str, release_id: str,
                                    classified_commits: Dict[str, List[CommitInfo]],
                                    ai_success: bool, ai_error: Optional[str] = None):
        """
        è¾“å‡ºGitHub Actionsæ‘˜è¦ä¿¡æ¯
        
        Args:
            mode: è¿è¡Œæ¨¡å¼
            version: ç‰ˆæœ¬å·
            release_id: Release ID
            classified_commits: åˆ†ç±»åçš„æäº¤
            ai_success: AIæ˜¯å¦æˆåŠŸ
            ai_error: AIé”™è¯¯ä¿¡æ¯
        """
        # è¾“å‡ºåˆ°GitHub Actions Step Summary
        step_summary_file = os.getenv('GITHUB_STEP_SUMMARY')
        if step_summary_file:
            try:
                total_commits = sum(len(commits) for commits in classified_commits.values())
                
                summary_content = f"""# ğŸ¤– AIå˜æ›´æ—¥å¿—ç”ŸæˆæŠ¥å‘Š

## ğŸ“‹ æ‰§è¡Œæ¦‚è§ˆ
- **ç‰ˆæœ¬å·**: `{version}`
- **è¿è¡Œæ¨¡å¼**: `{mode.value}`
- **Release ID**: `{release_id}`
- **AIçŠ¶æ€**: {'âœ… æˆåŠŸ' if ai_success else 'âŒ å¤±è´¥'}
- **ç”Ÿæˆæ–¹å¼**: {'ğŸ§  AIæ™ºèƒ½ç”Ÿæˆ' if ai_success else 'ğŸ“ åŸºç¡€è§„åˆ™ç”Ÿæˆ'}
- **å¤„ç†æäº¤æ•°**: `{total_commits}`

## ğŸ“Š æäº¤åˆ†ç±»ç»Ÿè®¡
"""
                
                for category, commits_list in classified_commits.items():
                    if commits_list:
                        title, _ = self.templates["categories"][category]
                        summary_content += f"- **{title}**: {len(commits_list)} ä¸ªæäº¤\n"
                
                if not ai_success and ai_error:
                    summary_content += f"\n## âš ï¸ æ³¨æ„äº‹é¡¹\n- AI APIè°ƒç”¨å¤±è´¥: {ai_error}\n- å·²ä½¿ç”¨åŸºç¡€è§„åˆ™ç”Ÿæˆå˜æ›´æ—¥å¿—\n"
                
                summary_content += f"\n## âœ… æ‰§è¡Œç»“æœ\nå˜æ›´æ—¥å¿—å·²æˆåŠŸæ›´æ–°åˆ° Release é¡µé¢\n"
                
                with open(step_summary_file, 'w', encoding='utf-8') as f:
                    f.write(summary_content)
                
                self.logger.info("âœ… GitHub Actionsæ‘˜è¦å·²ç”Ÿæˆ")
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ ç”ŸæˆGitHub Actionsæ‘˜è¦å¤±è´¥: {e}")
        
        # è¾“å‡ºGitHub Actionså˜é‡
        github_output_file = os.getenv('GITHUB_OUTPUT')
        if github_output_file:
            try:
                with open(github_output_file, 'a', encoding='utf-8') as f:
                    f.write(f"ai_success={str(ai_success).lower()}\n")
                    f.write(f"total_commits={sum(len(commits) for commits in classified_commits.values())}\n")
                    f.write(f"generation_mode={'ai' if ai_success else 'basic'}\n")
            except Exception as e:
                self.logger.warning(f"âš ï¸ è®¾ç½®GitHub Actionsè¾“å‡ºå˜é‡å¤±è´¥: {e}")
    
    def get_all_releases(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰Releaseä¿¡æ¯
        
        Returns:
            Releaseåˆ—è¡¨
        """
        self.logger.info("ğŸ“‹ è·å–æ‰€æœ‰Releaseä¿¡æ¯...")
        
        all_releases = []
        page = 1
        per_page = 30
        
        while True:
            url = f"{self.github_api_base}/repos/{self.repo}/releases"
            params = {
                'page': page,
                'per_page': per_page
            }
            
            response = requests.get(url, headers=self.github_headers, params=params)
            
            if response.status_code != 200:
                error_msg = f"æ— æ³•è·å–Releaseåˆ—è¡¨: {response.json().get('message', 'æœªçŸ¥é”™è¯¯')}"
                self.logger.error(f"âŒ {error_msg}")
                raise Exception(error_msg)
            
            releases = response.json()
            
            if not releases:
                break
            
            all_releases.extend(releases)
            page += 1
            
            # æ˜¾ç¤ºè·å–è¿›åº¦
            self.logger.info(f"ğŸ“„ å·²è·å– {len(all_releases)} ä¸ªRelease...")
        
        self.logger.info(f"âœ… æ€»å…±è·å–åˆ° {len(all_releases)} ä¸ªRelease")
        
        return all_releases
    
    def print_realtime_summary(self, release_tag: str, current: int, total: int, 
                              success: bool, ai_success: bool, error_msg: Optional[str] = None):
        """
        å®æ—¶è¾“å‡ºå¤„ç†æ‘˜è¦
        
        Args:
            release_tag: Releaseæ ‡ç­¾
            current: å½“å‰å¤„ç†çš„åºå·
            total: æ€»æ•°
            success: æ˜¯å¦æˆåŠŸ
            ai_success: AIæ˜¯å¦æˆåŠŸ
            error_msg: é”™è¯¯ä¿¡æ¯
        """
        elapsed_time = time.time() - self.batch_stats.start_time
        
        # æ›´æ–°ç»Ÿè®¡
        if success:
            self.batch_stats.success_count += 1
            if ai_success:
                self.batch_stats.ai_success_count += 1
        else:
            self.batch_stats.error_count += 1
        
        # è®¡ç®—è¿›åº¦
        progress = (current / total) * 100
        
        # ä¼°ç®—å‰©ä½™æ—¶é—´
        if current > 0:
            avg_time = elapsed_time / current
            remaining_time = avg_time * (total - current)
            remaining_str = f"{remaining_time/60:.1f}åˆ†é’Ÿ" if remaining_time > 60 else f"{remaining_time:.0f}ç§’"
        else:
            remaining_str = "è®¡ç®—ä¸­..."
        
        # å®æ—¶æ‘˜è¦è¾“å‡º
        print(f"\n{'='*80}")
        print(f"ğŸ”„ æ‰¹é‡å¤„ç†è¿›åº¦: {current}/{total} ({progress:.1f}%)")
        print(f"ğŸ“¦ å½“å‰å¤„ç†: {release_tag}")
        print(f"{'='*80}")
        
        print(f"ğŸ“Š å½“å‰ç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸ: {self.batch_stats.success_count}")
        print(f"  ğŸ§  AIæˆåŠŸ: {self.batch_stats.ai_success_count}")
        print(f"  âŒ å¤±è´¥: {self.batch_stats.error_count}")
        print(f"  â© è·³è¿‡: {self.batch_stats.skipped_count}")
        
        print(f"â±ï¸  æ—¶é—´ä¿¡æ¯:")
        print(f"  å·²ç”¨æ—¶: {elapsed_time/60:.1f}åˆ†é’Ÿ")
        print(f"  é¢„è®¡å‰©ä½™: {remaining_str}")
        
        if success:
            status = "ğŸ§  AIæ™ºèƒ½ç”Ÿæˆ" if ai_success else "ğŸ“ åŸºç¡€è§„åˆ™ç”Ÿæˆ"
            print(f"âœ… {release_tag} å¤„ç†å®Œæˆ - {status}")
        elif error_msg == "SKIPPED":
            print(f"â© {release_tag} å·²è·³è¿‡ - æ— éœ€ä¼˜åŒ–")
            self.batch_stats.skipped_count += 1
        else:
            print(f"âŒ {release_tag} å¤„ç†å¤±è´¥")
            if error_msg:
                print(f"   é”™è¯¯: {error_msg}")
        
        print(f"{'='*80}\n")
        
        # åˆ·æ–°è¾“å‡ºç¡®ä¿å®æ—¶æ˜¾ç¤º
        sys.stdout.flush()
    
    def process_single_release(self, release_data: Dict[str, Any]) -> Tuple[bool, bool, Optional[str]]:
        """
        å¤„ç†å•ä¸ªRelease
        
        Args:
            release_data: Releaseæ•°æ®
            
        Returns:
            Tuple[æ˜¯å¦æˆåŠŸ, AIæ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯]
        """
        tag_name = release_data['tag_name']
        release_id = str(release_data['id'])
        original_changelog = release_data.get('body', '')
        
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
            need_optimize, processed_changelog = self.check_optimization_status(
                RunMode.MANUAL_OPTIMIZE, original_changelog
            )
            
            if not need_optimize:
                return True, False, "SKIPPED"
            
            # è·å–Gitæäº¤ä¿¡æ¯
            commits, commit_range, commit_count = self.get_git_commits(tag_name)
            self.batch_stats.total_commits += commit_count
            
            # åˆ†ç±»æäº¤
            classified_commits = self.classify_commits(commits)
            
            # å°è¯•AIåˆ†æ
            ai_analysis = self.call_deepseek_api(commits)
            ai_success = ai_analysis is not None
            
            # ç”Ÿæˆå˜æ›´æ—¥å¿—
            if ai_success:
                changelog = self.generate_changelog_with_ai(tag_name, ai_analysis, processed_changelog, commits)
            else:
                changelog = self.generate_changelog_basic(tag_name, classified_commits, processed_changelog)
            
            # æ›´æ–°Release
            success = self.update_release_changelog(release_id, changelog)
            
            return success, ai_success, None
            
        except Exception as e:
            return False, False, str(e)
    
    def run_batch_processing(self) -> bool:
        """
        è¿è¡Œæ‰¹é‡å¤„ç†æ‰€æœ‰Release
        
        Returns:
            æ˜¯å¦æ•´ä½“æ‰§è¡ŒæˆåŠŸ
        """
        self.logger.info("ğŸ”„ å¼€å§‹æ‰¹é‡å¤„ç†æ‰€æœ‰Release...")
        
        try:
            # è·å–æ‰€æœ‰Release
            all_releases = self.get_all_releases()
            
            if not all_releases:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•Release")
                return True
            
            self.batch_stats.total_releases = len(all_releases)
            
            print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(all_releases)} ä¸ªRelease")
            print(f"â±ï¸ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("="*80)
            
            # é€ä¸ªå¤„ç†Release
            for i, release_data in enumerate(all_releases, 1):
                tag_name = release_data['tag_name']
                
                try:
                    success, ai_success, error_msg = self.process_single_release(release_data)
                    self.print_realtime_summary(tag_name, i, len(all_releases), success, ai_success, error_msg)
                    
                    # æ·»åŠ é€‚å½“çš„å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
                    if i < len(all_releases):
                        time.sleep(2)
                        
                except Exception as e:
                    self.logger.error(f"âŒ å¤„ç† {tag_name} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    self.print_realtime_summary(tag_name, i, len(all_releases), False, False, str(e))
                
                self.batch_stats.processed_releases = i
            
            # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
            self.print_final_batch_summary()
            
            # è¾“å‡ºGitHub Actionså˜é‡
            self._output_batch_github_actions()
            
            # åˆ¤æ–­æ•´ä½“æ˜¯å¦æˆåŠŸï¼ˆæˆåŠŸç‡è¶…è¿‡80%ï¼‰
            success_rate = self.batch_stats.success_count / len(all_releases)
            return success_rate >= 0.8
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            return False
    
    def print_final_batch_summary(self):
        """è¾“å‡ºæœ€ç»ˆæ‰¹é‡å¤„ç†æ‘˜è¦"""
        elapsed_time = time.time() - self.batch_stats.start_time
        success_rate = (self.batch_stats.success_count / self.batch_stats.total_releases) * 100
        ai_rate = (self.batch_stats.ai_success_count / max(1, self.batch_stats.success_count)) * 100
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"{'='*80}")
        
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"  ğŸ“¦ æ€»Releaseæ•°: {self.batch_stats.total_releases}")
        print(f"  âœ… æˆåŠŸå¤„ç†: {self.batch_stats.success_count}")
        print(f"  ğŸ§  AIæˆåŠŸ: {self.batch_stats.ai_success_count}")
        print(f"  â© è·³è¿‡: {self.batch_stats.skipped_count}")
        print(f"  âŒ å¤±è´¥: {self.batch_stats.error_count}")
        print(f"  ğŸ“ æ€»æäº¤æ•°: {self.batch_stats.total_commits}")
        
        print(f"ğŸ“ˆ æˆåŠŸç‡:")
        print(f"  ğŸ“¦ å¤„ç†æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"  ğŸ§  AIæˆåŠŸç‡: {ai_rate:.1f}%")
        
        print(f"â±ï¸  æ—¶é—´ç»Ÿè®¡:")
        print(f"  æ€»ç”¨æ—¶: {elapsed_time/60:.1f}åˆ†é’Ÿ")
        print(f"  å¹³å‡æ¯ä¸ª: {elapsed_time/self.batch_stats.total_releases:.1f}ç§’")
        print(f"  å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        print(f"{'='*80}")
    
    def _output_batch_github_actions(self):
        """è¾“å‡ºæ‰¹é‡å¤„ç†çš„GitHub Actionså˜é‡"""
        github_output_file = os.getenv('GITHUB_OUTPUT')
        if github_output_file:
            try:
                with open(github_output_file, 'a', encoding='utf-8') as f:
                    f.write(f"ai_success={self.batch_stats.ai_success_count > 0}\n")
                    f.write(f"total_commits={self.batch_stats.total_commits}\n")
                    f.write(f"generation_mode=batch\n")
                    f.write(f"processed_releases={self.batch_stats.processed_releases}\n")
            except Exception as e:
                self.logger.warning(f"âš ï¸ è®¾ç½®GitHub Actionsè¾“å‡ºå˜é‡å¤±è´¥: {e}")
        
        # GitHub Actions Step Summary
        step_summary_file = os.getenv('GITHUB_STEP_SUMMARY')
        if step_summary_file:
            try:
                elapsed_time = time.time() - self.batch_stats.start_time
                success_rate = (self.batch_stats.success_count / self.batch_stats.total_releases) * 100
                
                summary_content = f"""# ğŸ”„ æ‰¹é‡AIå˜æ›´æ—¥å¿—ç”ŸæˆæŠ¥å‘Š

## ğŸ“Š å¤„ç†ç»Ÿè®¡
- **æ€»Releaseæ•°**: `{self.batch_stats.total_releases}`
- **æˆåŠŸå¤„ç†**: `{self.batch_stats.success_count}`
- **AIæ™ºèƒ½ç”Ÿæˆ**: `{self.batch_stats.ai_success_count}`
- **è·³è¿‡**: `{self.batch_stats.skipped_count}`
- **å¤±è´¥**: `{self.batch_stats.error_count}`

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡
- **å¤„ç†æˆåŠŸç‡**: `{success_rate:.1f}%`
- **æ€»å¤„ç†æ—¶é—´**: `{elapsed_time/60:.1f}åˆ†é’Ÿ`
- **æ€»æäº¤æ•°**: `{self.batch_stats.total_commits}`

## âœ… æ‰§è¡Œç»“æœ
{'âœ… æ‰¹é‡å¤„ç†æˆåŠŸå®Œæˆ' if success_rate >= 80 else 'âš ï¸ æ‰¹é‡å¤„ç†éƒ¨åˆ†å¤±è´¥'}
"""
                
                with open(step_summary_file, 'w', encoding='utf-8') as f:
                    f.write(summary_content)
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ ç”ŸæˆGitHub Actionsæ‘˜è¦å¤±è´¥: {e}")

    def run(self, version: Optional[str] = None, release_id: Optional[str] = None, 
           tag: Optional[str] = None, target: Optional[str] = None,
           event_name: str = "workflow_dispatch") -> bool:
        """
        è¿è¡ŒAIå˜æ›´æ—¥å¿—ç”Ÿæˆæµç¨‹
        
        Args:
            version: ç‰ˆæœ¬å· (è‡ªåŠ¨è§¦å‘æ—¶ä½¿ç”¨)
            release_id: Release ID (è‡ªåŠ¨è§¦å‘æ—¶ä½¿ç”¨)
            tag: æ ‡ç­¾ (æ—§ç‰ˆå…¼å®¹)
            target: ç›®æ ‡ç‰ˆæœ¬æˆ–æ ‡ç­¾ (æ–°ç‰ˆæ‰‹åŠ¨è§¦å‘ä½¿ç”¨)
            event_name: äº‹ä»¶åç§°
            
        Returns:
            æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
        """
        try:
            # 1. éªŒè¯å‚æ•°
            mode, final_version, final_release_id = self.validate_params(
                version, release_id, tag, target, event_name
            )
            
            # 2. æ‰¹é‡å¤„ç†æ¨¡å¼
            if mode == RunMode.BATCH_ALL:
                return self.run_batch_processing()
            
            # 3. å•ä¸ªReleaseå¤„ç†æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            # è·å–Releaseä¿¡æ¯
            final_release_id, original_changelog = self.get_release_info(mode, final_version, final_release_id)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
            need_optimize, processed_changelog = self.check_optimization_status(mode, original_changelog)
            
            if not need_optimize:
                self.logger.info("ğŸš« æ— éœ€ä¼˜åŒ–ï¼Œæµç¨‹ç»“æŸ")
                return True
            
            # è·å–Gitæäº¤ä¿¡æ¯
            commits, commit_range, commit_count = self.get_git_commits(final_version)
            
            # åˆ†ç±»æäº¤
            classified_commits = self.classify_commits(commits)
            
            # å°è¯•AIåˆ†æ
            ai_analysis = self.call_deepseek_api(commits)
            ai_success = ai_analysis is not None
            ai_error = None if ai_success else "APIè°ƒç”¨å¤±è´¥"
            
            # ç”Ÿæˆå˜æ›´æ—¥å¿—
            if ai_success:
                changelog = self.generate_changelog_with_ai(final_version, ai_analysis, processed_changelog, commits)
            else:
                changelog = self.generate_changelog_basic(final_version, classified_commits, processed_changelog)
            
            # æ›´æ–°Release
            success = self.update_release_changelog(final_release_id, changelog)
            
            # ç”Ÿæˆå’Œè¾“å‡ºæ‘˜è¦æŠ¥å‘Š
            report = self.generate_summary_report(mode, final_version, final_release_id, 
                                                 classified_commits, ai_success, ai_error)
            
            # è¾“å‡ºåˆ°æ§åˆ¶å°
            print(report)
            
            # è¾“å‡ºåˆ°GitHub Actions
            self.output_github_actions_summary(mode, final_version, final_release_id, 
                                             classified_commits, ai_success, ai_error)
            
            return success
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="AIå˜æ›´æ—¥å¿—ç”Ÿæˆå™¨")
    
    # æ–°ç‰ˆå‚æ•°
    parser.add_argument("--target", help="ç›®æ ‡ç‰ˆæœ¬æˆ–æ ‡ç­¾ï¼ˆæ‰‹åŠ¨è§¦å‘ä½¿ç”¨ï¼Œå¦‚ï¼šv1.0.0 æˆ– latestï¼‰")
    
    # å…¼å®¹æ—§ç‰ˆå‚æ•°
    parser.add_argument("--version", help="ç‰ˆæœ¬å·ï¼ˆè‡ªåŠ¨è§¦å‘ä½¿ç”¨ï¼‰")
    parser.add_argument("--release-id", help="Release IDï¼ˆè‡ªåŠ¨è§¦å‘ä½¿ç”¨ï¼‰")
    parser.add_argument("--tag", help="æ ‡ç­¾ï¼ˆæ—§ç‰ˆå…¼å®¹ï¼‰")
    
    # å…¶ä»–å‚æ•°
    parser.add_argument("--event-name", default="workflow_dispatch", help="äº‹ä»¶åç§°")
    parser.add_argument("--repo", help="GitHubä»“åº“å(owner/repo)")
    parser.add_argument("--github-token", help="GitHub Token")
    parser.add_argument("--deepseek-api-key", help="DeepSeek API Key")
    
    args = parser.parse_args()
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    github_token = args.github_token or os.getenv("GITHUB_TOKEN")
    deepseek_api_key = args.deepseek_api_key or os.getenv("DEEPSEEK_API_KEY")
    repo = args.repo or os.getenv("GITHUB_REPOSITORY")
    
    if not github_token:
        print("âŒ ç¼ºå°‘GitHub Tokenï¼Œè¯·è®¾ç½®GITHUB_TOKENç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨--github-tokenå‚æ•°")
        sys.exit(1)
    
    if not deepseek_api_key:
        print("âŒ ç¼ºå°‘DeepSeek API Keyï¼Œè¯·è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨--deepseek-api-keyå‚æ•°")
        sys.exit(1)
    
    if not repo:
        print("âŒ ç¼ºå°‘ä»“åº“ä¿¡æ¯ï¼Œè¯·è®¾ç½®GITHUB_REPOSITORYç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨--repoå‚æ•°")
        sys.exit(1)
    
    # åˆ›å»ºç”Ÿæˆå™¨å¹¶è¿è¡Œ
    generator = AIChangelogGenerator(github_token, deepseek_api_key, repo)
    
    success = generator.run(
        version=args.version,
        release_id=args.release_id,
        tag=args.tag,
        target=args.target,
        event_name=args.event_name
    )
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
